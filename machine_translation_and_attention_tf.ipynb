{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Translation and Attention\n",
    "In this notebook, we will implement a model for neural machine translation (NMT) with attention. This notebook is adapted from the [TensorFlow tutorial on NMT](https://www.tensorflow.org/tutorials/seq2seq) at  as well as the [TensorFlow NMT package](https://github.com/tensorflow/nmt/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import collections\n",
    "from functools import partial\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import zipfile\n",
    "\n",
    "import numpy as np\n",
    "from six.moves import urllib\n",
    "from six.moves import xrange\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Helper TensorFlow functions\n",
    "from utils import maybe_download\n",
    "\n",
    "# The encoder-decoder architecture\n",
    "from nmt.model import AttentionalModel, LSTMCell\n",
    "from nmt.utils import vocab_utils\n",
    "from nmt.train import train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "We'll train our model on a small-scale dataset: an English-Vietnamese parallel corpus of TED talks (133K sentence pairs) provided by the IWSLT Evaluation Campaign (https://sites.google.com/site/iwsltevaluation2015/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found and verified datasets/nmt_data_vi/train.en\n",
      "Found and verified datasets/nmt_data_vi/train.vi\n",
      "Found and verified datasets/nmt_data_vi/tst2012.en\n",
      "Found and verified datasets/nmt_data_vi/tst2012.vi\n",
      "Found and verified datasets/nmt_data_vi/tst2013.en\n",
      "Found and verified datasets/nmt_data_vi/tst2013.vi\n",
      "Found and verified datasets/nmt_data_vi/vocab.en\n",
      "Found and verified datasets/nmt_data_vi/vocab.vi\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'vocab.vi'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_dir = os.path.join('datasets', 'nmt_data_vi')\n",
    "site_prefix = \"https://nlp.stanford.edu/projects/nmt/data/\"\n",
    "\n",
    "maybe_download(site_prefix + 'iwslt15.en-vi/train.en', out_dir, 13603614)\n",
    "maybe_download(site_prefix + 'iwslt15.en-vi/train.vi', out_dir, 18074646)\n",
    "\n",
    "maybe_download(site_prefix + 'iwslt15.en-vi/tst2012.en', out_dir, 140250)\n",
    "maybe_download(site_prefix + 'iwslt15.en-vi/tst2012.vi', out_dir, 188396)\n",
    "\n",
    "maybe_download(site_prefix + 'iwslt15.en-vi/tst2013.en', out_dir, 132264)\n",
    "maybe_download(site_prefix + 'iwslt15.en-vi/tst2013.vi', out_dir, 183855)\n",
    "\n",
    "maybe_download(site_prefix + 'iwslt15.en-vi/vocab.en', out_dir, 139741)\n",
    "maybe_download(site_prefix + 'iwslt15.en-vi/vocab.vi', out_dir, 46767)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to NMT\n",
    "\n",
    "<figure>\n",
    "    <img src='images/encdec.jpg' alt='missing' />\n",
    "    <figcaption>**Figure 1.** Example of a general, *encoder-decoder* approach to NMT. An encoder converts a source sentence into a representation which is passed through a decoder to produce a translation</figcaption>\n",
    "</figure>\n",
    "\n",
    "A neural machine translation (NMT) system reads in a source sentence using an *encoder*, and then uses a *decoder* to emit a translation. NMT models vary in terms of their exact architectures. A natural choice for sequential data is the recurrent neural network (RNN). Usually an RNN is used for both the encoder and decoder. The RNN models, however, differ in terms of: (a) directionality – unidirectional or bidirectional (whether they read the source sentence in forwards or forwards and backwards); (b) depth – single- or multi-layer; and (c) type – often either a vanilla RNN, a Long Short-term Memory (LSTM), or a gated recurrent unit (GRU).\n",
    "\n",
    "We will consider a deep multi-layer RNN which is bi-directional (it reads the input sequence both forwards and backwards) and uses LSTM units with attention. At a high level, the NMT model consists of two recurrent neural networks: the encoder recurrent network simply consumes the input source words without making any prediction; the decoder, on the other hand, processes the target sentence while predicting the next words.\n",
    "\n",
    "<figure>\n",
    "    <img src='images/seq2seq.jpg' alt='missing' />\n",
    "    <figcaption>**Figure 2.** Example of a neural machine translation system for translating a source sentence \"I am a student\" into a target sentence \"Je suis étudiant\".  Here, $<s>$ marks the start of the decoding process while $</s>$ tells the decoder to stop.\n",
    "    </figcaption>\n",
    "</figure>\n",
    "\n",
    "At the bottom layer, the encoder and decoder recurrent networks receive as input the following: first, the source sentence, then a boundary marker $</s>$ which indicates the transition from the encoding to the decoding mode, and the target sentence. We now go into the details of how the model deals with source and target sentences.\n",
    "\n",
    "### Embedding\n",
    "Given the categorical nature of words, the model must first look up the source and target embeddings to retrieve the corresponding word representations. For this embedding layer to work, a vocabulary is first chosen for each language. Usually, a vocabulary size $V$ is selected, and only the most frequent $V$ words in the corpus are treated as unique. All other words are converted to an \"unknown\" token $<$UNK$>$ and all get the same embedding. The embedding weights, one set per language, are usually learned during training (but pretrained word embeddings may be used instead).\n",
    "\n",
    "### Encoder\n",
    "Once retrieved, the word embeddings are then fed as input into the main network, which consists of two multi-layer recurrent neural networks -- an encoder for the source language and a decoder for the target language. These two networks, in principle, can share the same weights; however, in practice, we often use two different sets of parameters (such models do a better job when fitting large training datasets). The encoder uses zero vectors as its starting states (before it sees the source sequence). In TensorFlow:\n",
    "\n",
    "    # Build RNN cell\n",
    "    encoder_cell = YourEncoderRNNCell(num_units)\n",
    "\n",
    "    # Run Dynamic RNN\n",
    "    #   encoder_outputs: [max_time, batch_size, num_units]\n",
    "    #   encoder_state: [batch_size, num_units]\n",
    "    encoder_outputs, encoder_state = tf.nn.dynamic_rnn(\n",
    "        encoder_cell, encoder_emb_inp,\n",
    "        sequence_length=source_sequence_length, time_major=True)\n",
    "\n",
    "### Decoder\n",
    "The decoder also needs to have access to the source information, and one simple way to achieve that is to initialize it with the last hidden state of the encoder, `encoder_state`. In Figure 2, we pass the hidden state at the source word \"student\" to the decoder side.\n",
    "\n",
    "    # Build RNN cell\n",
    "    decoder_cell = tf.nn.rnn_cell.BasicLSTMCell(num_units)\n",
    "    \n",
    "    # Helper\n",
    "    helper = tf.contrib.seq2seq.TrainingHelper(\n",
    "        decoder_emb_inp, decoder_lengths, time_major=True)\n",
    "\n",
    "    # Decoder\n",
    "    decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "        decoder_cell, helper, encoder_state, output_layer=projection_layer)\n",
    "    \n",
    "    # Dynamic decoding\n",
    "    outputs, _ = tf.contrib.seq2seq.dynamic_decode(decoder, ...)\n",
    "    logits = outputs.rnn_output\n",
    "\n",
    "### Loss\n",
    "Given the logits above, we are now ready to compute the training loss:\n",
    "\n",
    "    xent = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=decoder_outputs, logits=logits)\n",
    "    train_loss = (tf.reduce_sum(crossent * target_weights) / batch_size)\n",
    "\n",
    "Here, target_weights is a zero-one matrix of the same size as decoder_outputs. It masks padding positions outside of the target sequence lengths with values 0.\n",
    "\n",
    "Important note: It's worth pointing out that we should divide the loss by `batch_size`, so our hyperparameters are \"invariant\" to `batch_size`. Some people divide the loss by (`batch_size * num_time_steps`), which plays down the errors made on short sentences. More subtly, the same hyperparameters (applied to the former way) can't be used for the latter way. For example, if both approaches use SGD with a learning of `1.0`, the latter approach effectively uses a much smaller learning rate of `1 / num_time_steps`.\n",
    "\n",
    "### How to generate translations at test time\n",
    "\n",
    "While you're training your NMT models (and once you have trained models), you can obtain translations given previously unseen source sentences. At test time, we only have access to the source sentence; i.e., `encoder_inputs`. There are many ways to perform decoding given those inputs. Decoding methods include greedy, sampling, and beam-search decoding. Here, we will discuss the greedy decoding strategy.\n",
    "\n",
    "The idea is simple and illustrated in Figure 3:\n",
    "\n",
    "1. We still encode the source sentence in the same way as during training to obtain an `encoder_state`, and this `encoder_state` is used to initialize the decoder.\n",
    "\n",
    "2. The decoding (translation) process is started as soon as the decoder receives a starting symbol $<$/s$>$.\n",
    "\n",
    "3. For each timestep on the decoder side, we treat the recurrent network's output as a set of logits. We choose the most likely word, the id associated with the maximum logit value, as the emitted word (this is the \"greedy\" behavior). For example in Figure 3, the word \"moi\" has the highest translation probability in the first decoding step. We then feed this word as input to the next timestep. (At training time, however, we may feed in the true target as input to the next timestep in a process called *teacher forcing*.)\n",
    "\n",
    "4. The process continues until the end-of-sentence marker $<$/s$>$ is produced as an output symbol.\n",
    "\n",
    "<figure>\n",
    "    <img src='images/greedy_dec.jpg' alt='missing' />\n",
    "    <figcaption>**Figure 3.** Example of how a trained NMT model produces a translation for a source sentence \"Je suis étudiant\" using greedy search.\n",
    "    </figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Attention\n",
    "\n",
    "The attention mechanism was first introduced by Bahdanau et al., 2015 [1] and then later refined by Luong et al., 2015 [2] and others. The key idea of the attention mechanism is to establish direct short-cut connections between the target and the source by paying \"attention\" to relevant source content as we translate (produce output tokens). A nice byproduct of the attention mechanism is an easy-to-visualize alignment matrix between the source and target sentences that we will visualize at the end of this notebook.\n",
    " \n",
    "Remember that in a vanilla seq2seq model, we pass the last source state $h_{s_{T_s}}$ from the encoder to the decoder when starting the decoding process. This works well for short and medium-length sentences; however, for long sentences, the single fixed-size hidden state becomes an information bottleneck. Instead of discarding all of the hidden states computed in the source RNN, the attention mechanism provides an approach that allows the decoder to peek at them (treating them as a dynamic memory of the source information). By doing so, the attention mechanism improves the translation of longer sentences. Nowadays, attention mechanisms are the *de facto* standard and have been successfully applied to many other tasks (including image caption generation, speech recognition, and text summarization).\n",
    "\n",
    "<figure>\n",
    "    <img src='images/att.jpg' alt='missing' />\n",
    "    <figcaption>**Figure 4.** Example of an attention-based NMT system with the first step of the attention computation in detail. For clarity, the embedding and projection layers are omitted.\n",
    "    </figcaption>\n",
    "</figure>\n",
    "\n",
    "### How do we actually attend over the input sequence?\n",
    "\n",
    "There are many different ways of formalizing attention. These variants depend on the form of a *scoring* function and an *attention* function (and on whether the previous state of the decoder $h_{t_{i-1}}$ is used instead of $h_{t_{i}}$ in the scoring function as originally suggested in Bahdanau et al. (2015); **we will stick to using $h_{t_{i}}$** in this notebook). Luong et al. (2015) demonstrate that only a few choices actually matter:\n",
    "\n",
    "1. First, the basic form of attention, i.e., **direct connections between target and source**, needs to be present. \n",
    "\n",
    "2. Second, it's important to **feed the attention vector to the next timestep** to inform the network about past attention decisions.\n",
    "\n",
    "3. Lastly, **choices of the scoring function** can often result in different performance. See Luong et al. (2015) for further details.\n",
    "\n",
    "### A general framework for computing attention\n",
    "\n",
    "The attention computation happens at every decoder time step. It consists of the following stages:\n",
    "\n",
    "1. The current target (encoder) hidden state $h_{t_i}$ is compared with all source (decoder) states $h_{s_j}$ to derive *attention weights* $\\alpha_{ij}$.\n",
    "2. Based on the attention weights we compute a *context vector* $c_{i}$ as the weighted average of the source states.\n",
    "3. We combine the context vector $c_{i}$ with the current target hidden state $h_{s_j}$ to yield the final *attention vector* $a_t$.\n",
    "4. The attention vector $a_i$ is fed as an input to the next time step (*input feeding*). \n",
    "\n",
    "The first three steps can be summarized by the equations below:\n",
    "\n",
    "$$\\large\\begin{align*}\n",
    "\\alpha_{ij} &= \\frac{\n",
    "    \\exp(\\text{score}(h_{t_i}, h_{s_j}))\n",
    "}{\n",
    "    \\sum_{k=1}^{T_s}{\\exp(\\text{score}(h_{t_i}, h_{s_k}))}\n",
    "} \\tag{attention weights} \\\\\\\\\n",
    "c_{i} &= \\sum_{j=1}^{T_s} \\alpha_{ij} h_{s_j} \\tag{context vector} \\\\\\\\\n",
    "a_{i} &= f(c_{i}, h_{t_i}) \\tag{attention vector} \\\\\\\\\n",
    "\\end{align*}$$\n",
    "\n",
    "Here, the function `score` is used to compare the target hidden state $h_{t_i}$ with each of the source hidden states $h_{s_j}$, and the result is normalized over the source timesteps $j = 1, \\dots, T_s$ to produce attention weights $\\alpha_{ij}$ (which define a distribution over source positions $j$ for a given source timestep $i$). (There are various choices of the scoring function; we will consider three below.) Note that we make use of the current decoder (or *target*) hidden state $h_{t_i}$, which is computed as a function of the previous hidden state $h_{t_{i-1}}$, the embedding of the input token $x_{i}$ (which is either the emission or the ground truth token from the previous timestep) using the standard formula for a recurrent cell. Optionally, in the case of *input feeding*, we combine $h_{t_{i-1}}$ with the context vector from the previous timestep, $c_{t_{i-1}}$ (which may require a change in the size of the kernel matrix, depending on how the combination is implemented). The encoder (or *source*) hidden states $h_{s_j}$ for $j=1, \\dots T_s$ are similarly the standard hidden state for a recurrent cell.\n",
    "\n",
    "We can also vectorize the computation of the context vector $c_i$ for every target timestep as follows: Given the source hidden states $h_{s_1}, \\dots, h_{s_{T_s}}$, we construct a matrix $H_s$ of size `hidden_size` $\\times$ `input_seq_len` by stacking the source hidden states into columns. Attention allows us to dynamically weight certain timesteps of the input sequence in a fixed size vector $c_i$ by taking a convex combination of the columns of $H_s$. In particular, we calculate a nonzero and normalized attention weight vector $\\vec{\\alpha}_i = [\\alpha_{i1}, \\dots, \\alpha_{iT_s}]^T$ that weights the source hidden states in the computation\n",
    "\n",
    "$$\\large c_i = H_s\\vec{\\alpha}_i~.$$\n",
    "\n",
    "\n",
    "\n",
    "The attention vector $a_i$ is used to derive the softmax logits and thereafter the loss by transformation under a function $f$.The function $f$ is commonly the a concatenation followed by $\\tanh$ layer:\n",
    "\n",
    "$$\\large a_{i} = \\tanh(W_a[c_i; h_{t_i}])$$\n",
    "\n",
    "but could take other forms. We then compute the predictive distribution over output tokens as\n",
    "\n",
    "$$\\large p(y_i \\mid y_1, \\dots y_{i-1}, x_i) = \\text{softmax}(W_s a_{i})~.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1. LSTM cell with attention (8 pts)\n",
    "\n",
    "In the block below, you will implement the method `call`, which computes a single step of an LSTM cell using a method `attention` that computes an attention vector with some score function, as described above. **Complete the skeleton below**; assume inputs is already the input embedding (i.e., there is no need to construct an embedding matrix)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMCellWithAttention(LSTMCell):\n",
    "    \n",
    "    def __init__(self, num_units, memory):\n",
    "        print(num_units)\n",
    "        super(LSTMCellWithAttention, self).__init__(num_units)\n",
    "        self.memory = memory\n",
    "        \n",
    "    def attention(self):\n",
    "        raise NotImplementedError(\"The subclass must implement this method!\")\n",
    "\n",
    "    def call(self, inputs, state):\n",
    "        \"\"\"Run this LSTM cell with attention on inputs, conditional on state.\"\"\"\n",
    "        \n",
    "        # Cell and hidden states of the LSTM\n",
    "        c, h = state\n",
    "        \n",
    "        # Source (encoder) states to attend over\n",
    "        source_states = self.memory\n",
    "        \n",
    "        # Cell activation (e.g., tanh, relu, etc.)\n",
    "        activation = self._activation\n",
    "        \n",
    "        # LSTM cell parameters\n",
    "        kernel = self._kernel\n",
    "        bias = self._bias\n",
    "        forget_bias = self._forget_bias\n",
    "        \n",
    "        ### YOUR CODE HERE\n",
    "        from tensorflow.python.ops import math_ops\n",
    "        from tensorflow.python.framework import constant_op\n",
    "        from tensorflow.python.ops import array_ops\n",
    "        from tensorflow.python.ops import nn_ops\n",
    "        sigmoid = math_ops.sigmoid\n",
    "        one = constant_op.constant(1, dtype=tf.int32)\n",
    "        attention_vector = self.attention(h,source_states)\n",
    "        gate_inputs = math_ops.matmul(\n",
    "                    array_ops.concat([inputs, h], 1), self._kernel)\n",
    "        gate_inputs = nn_ops.bias_add(gate_inputs, self._bias)\n",
    "        \n",
    "        # i = input_gate, j = new_input, f = forget_gate, o = output_gate\n",
    "        i, j, f, o = array_ops.split(\n",
    "        value=gate_inputs, num_or_size_splits=4, axis=one)\n",
    "\n",
    "        forget_bias_tensor = constant_op.constant(self._forget_bias, dtype=f.dtype)\n",
    "        # Note that using `add` and `multiply` instead of `+` and `*` gives a\n",
    "        # performance improvement. So using those at the cost of readability.\n",
    "        add = math_ops.add\n",
    "        multiply = math_ops.multiply\n",
    "        new_c = add(multiply(c, sigmoid(add(f, forget_bias_tensor))),\n",
    "                    multiply(sigmoid(i), self._activation(j)))\n",
    "        new_h = multiply(self._activation(new_c), sigmoid(o))\n",
    "        \n",
    "      \n",
    "        \n",
    "        ### END YOUR CODE\n",
    "        ### Your code should compute attention vector, new_c and new_h\n",
    "\n",
    "        # Adhering to convention\n",
    "        new_state = tf.contrib.rnn.LSTMStateTuple(new_c, new_h)\n",
    "    \n",
    "        return attention_vector, new_state "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can implement a \"dummy\" version of attention in order to test that the LSTM cell step function is working correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMCellWithDummyAttention(LSTMCellWithAttention):\n",
    "\n",
    "    def attention(self, target_state, source_states):\n",
    "        \"\"\"Just return the target state so that the update becomes the vanilla\n",
    "        LSTM update.\"\"\"\n",
    "        \n",
    "        return target_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2A. Dot-product Attention (8 pts)\n",
    "\n",
    "We first consider the simplest version of attention, which simply calculates the similarity between $h_{t_i}$ and $h_{s_j}$ by computing their dot product:\n",
    "\n",
    "$$\\large\\begin{align*}\n",
    "\\text{score}(h_{t_i}, h_{s_j})&=h_{t_i}^\\mathrm{\\,T}\\, h_{s_j}~.\n",
    "\\end{align*}$$\n",
    "\n",
    "This computation has no additional parameters, but it limits the expressivity of the model since its forces the input and output encodings to be close in order to have high score.\n",
    "\n",
    "For this question, **implement the __call__ function of the following LSTM cell using dot-product attention.** Your code should be less than ten lines and *not* make use of any higher-level primitives from `tf.nn` or `tf.layers`, etc. (6 pts). As a further step, **vectorize the operation** so that you can compute $\\text{score}(\\cdot, h_{s_j})$ for every word in the source sentence in parallel (2 pts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMCellWithDotProductAttention(LSTMCellWithAttention):\n",
    "        \n",
    "    def build(self, inputs_shape):\n",
    "        super(LSTMCellWithDotProductAttention, self).build(inputs_shape)\n",
    "        self._W_c = self.add_variable(\"W_c\", \n",
    "                                      shape=[self._num_units + self._num_units, \n",
    "                                             256])\n",
    "\n",
    "    def attention(self, target_state, source_states):\n",
    "        \"\"\"Return the attention vector computed from attending over\n",
    "        source_states using a function of target_state and source_states.\"\"\"\n",
    "        \n",
    "        ### YOUR CODE HERE\n",
    "        \n",
    "        tmp_target_state = tf.expand_dims(target_state,axis=1)\n",
    "        dot_prod =  tf.reduce_sum(tf.multiply(source_states,tmp_target_state), 2,keep_dims=True)\n",
    "        _max = tf.reduce_max(dot_prod,axis=2,keep_dims=True)\n",
    "        dot_prod = tf.subtract(dot_prod,_max)\n",
    "        exp_scores = tf.exp(dot_prod)\n",
    "        _sum = tf.reduce_sum(exp_scores,1)\n",
    "        tmp_sum = 1.0/tf.expand_dims(_sum,axis=1)\n",
    "        alpha = tf.multiply(exp_scores,tmp_sum)\n",
    "        alpha = tf.tile(alpha,(1,1,target_state.get_shape()[1]))   \n",
    "        c =  tf.reduce_sum(tf.multiply(alpha,source_states),axis=1,keep_dims=True)\n",
    "        c = tf.squeeze(c,[1])\n",
    "        \n",
    "       \n",
    "        ### END YOUR CODE\n",
    "        \n",
    "        ### Your code should compute the context vector c\n",
    "    \n",
    "      \n",
    "        attention_vector = tf.tanh(tf.matmul(tf.concat([c, target_state], -1), self._W_c))\n",
    "        \n",
    "       \n",
    "        return attention_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2B. Bilinear Attention (8 pts)\n",
    "\n",
    "To make the score function more expressive, we may consider using a bilinear function of the form\n",
    "\n",
    "$$\\large\\begin{align*}\n",
    "\\text{score}(h_{t_i}, h_{s_j})&=h_{t_i}^\\mathrm{\\,T} W_\\text{att} h_{s_j}~,\n",
    "\\end{align*}$$\n",
    "\n",
    "which transforms the source encoding $h_{s_j}$ by a linear transformation parameterized by $W_\\text{att}$ before taking the dot product. This formulation adds additional parameters that must be learned, but increases expressivity and also allows the source and target encodings to be of different dimensionality (if we so wish).\n",
    "\n",
    "For this question, **implement the __call__ function of the following LSTM cell using bilinear attention.** Your code should be less than ten lines and *not* make use of any higher-level primitives from `tf.nn`or `tf.layers`, etc. (6 pts). As a further step, **vectorize the operation** so that you can compute $\\text{score}(\\cdot, h_{s_j})$ for every word in the source sentence in parallel (2 pts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMCellWithBilinearAttention(LSTMCellWithAttention):\n",
    "    \n",
    "    def build(self, inputs_shape):\n",
    "        super(LSTMCellWithBilinearAttention, self).build(inputs_shape)\n",
    "        self._W_att = self.add_variable(\"W_att\", \n",
    "                                        shape=[self._num_units, \n",
    "                                               self._num_units])\n",
    "        self._W_c = self.add_variable(\"W_c\", \n",
    "                                      shape=[self._num_units + self._num_units, \n",
    "                                             256])\n",
    "\n",
    "    def attention(self, target_state, source_states):\n",
    "        \"\"\"Return the attention vector computed from attending over\n",
    "        source_states using a function of target_state and source_states.\"\"\"\n",
    "        \n",
    "        ### YOUR CODE HERE\n",
    "        \n",
    "        att_vec = tf.matmul( target_state, self._W_att )\n",
    "        tmp_att_vec = tf.expand_dims(att_vec,axis=1)\n",
    "        dot_prod = tf.reduce_sum(tf.multiply(tmp_att_vec,source_states), axis=2,keep_dims=True)\n",
    "        _max = tf.reduce_max(dot_prod,axis=2,keep_dims=True)\n",
    "        dot_prod = tf.subtract(dot_prod,_max)\n",
    "        exp_scores = tf.exp(dot_prod)\n",
    "        _sum = tf.reduce_sum(exp_scores,1)\n",
    "        tmp_sum = 1.0/tf.expand_dims(_sum,axis=1)\n",
    "        alpha = tf.multiply(exp_scores,tmp_sum)\n",
    "        alpha = tf.tile(alpha,(1,1,target_state.get_shape()[1]))   \n",
    "        c =  tf.reduce_sum(tf.multiply(alpha,source_states),axis=1,keep_dims=True)\n",
    "        c = tf.squeeze(c,[1])\n",
    "      \n",
    "        ### END YOUR CODE\n",
    "        \n",
    "        ### Your code should compute the context vector c\n",
    "        attention_vector = tf.tanh(tf.matmul(tf.concat([c, target_state], -1), self._W_c))\n",
    "       \n",
    "        \n",
    "        return attention_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2C. Feedforward Attention (8 pts)\n",
    "\n",
    "Instead of simply using a linear transformation, why don't we use an even more expressive feedforward neural network to compute the score?\n",
    "\n",
    "$$\\large\\begin{align*}\n",
    "\\text{score}(h_{t_i}, h_{s_j})&=W_{\\text{att}_2} \\tanh( W_{\\text{att}_1} [h_{t_i}; h_{s_j}])~,\n",
    "\\end{align*}$$\n",
    "\n",
    "where $[v_1; v_2]$ denotes a concatenation of the vectors $v_1$ and $v_2$, and $W_{\\text{att}_1}$ and $W_{\\text{att}_2}$ are learned parameter matrices. The feedforward approach typically has fewer parameters (depending on the size of the hidden layer) than the bilinear attention mechanism (which requires `source_embedding_dim` $\\times$ `target_embedding_dim` parameters).\n",
    "\n",
    "For this question, **implement the __call__ function of the following LSTM cell using feedforward attention.** Your code should be less than ten lines and *not* make use of any higher-level primitives from `tf.nn` or `tf.layers`, etc. (6 pts). As a further step, **vectorize the operation** so that you can compute $\\text{score}(\\cdot, h_{s_j})$ for every word in the source sentence in parallel (2 pts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMCellWithFeedForwardAttention(LSTMCellWithAttention):\n",
    "    \n",
    "    def build(self, inputs_shape):\n",
    "        super(LSTMCellWithFeedForwardAttention, self).build(inputs_shape)\n",
    "\n",
    "        self._W_att_1 = self.add_variable(\"W_att_1\", \n",
    "                                          shape=[self._num_units + self._num_units, \n",
    "                                                 self._num_units])\n",
    "        self._W_att_2 = self.add_variable(\"W_att_2\", \n",
    "                                          shape=[self._num_units, 1])\n",
    "        self._W_c = self.add_variable(\"W_c\", \n",
    "                                      shape=[self._num_units + self._num_units, \n",
    "                                             256])\n",
    "        \n",
    "    def attention(self, target_state, source_states):\n",
    "        \"\"\"Return the attention vector computed from attending over\n",
    "        source_states using a function of target_state and source_states.\"\"\"\n",
    "        \n",
    "        ### YOUR CODE HERE\n",
    "        sources_length = tf.shape(source_states)[1]\n",
    "        tmp_target_state = tf.expand_dims(target_state,axis=1)\n",
    "        target_repeated = tf.tile(tmp_target_state, (1,sources_length, 1))\n",
    "        tmp_1 = tf.concat([target_repeated, source_states], -1)\n",
    "        tmp_2 = tf.tanh(tf.tensordot(tmp_1,self._W_att_1,[[2],[0]]))\n",
    "        score = tf.tensordot(tmp_2,tf.transpose(self._W_att_2),[[2],[1]])\n",
    "        _max = tf.reduce_max(score,axis=2,keep_dims=True)\n",
    "        dot_prod = tf.subtract(score,_max)\n",
    "        exp_scores = tf.exp(score)\n",
    "        _sum = tf.reduce_sum(exp_scores, 1,keep_dims=True)\n",
    "        alpha = tf.divide(exp_scores,_sum)\n",
    "        c =  tf.reduce_sum(tf.multiply(alpha,source_states),axis=1,keep_dims=True)\n",
    "        c = tf.squeeze(c,[1])\n",
    "        \n",
    "        ### END YOUR CODE\n",
    "        \n",
    "        ### Your code should compute the context vector c\n",
    "        attention_vector = tf.tanh(tf.matmul(tf.concat([c, target_state], -1), self._W_c))\n",
    "        \n",
    "        return attention_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter settings\n",
    "\n",
    "You may find it useful to tune some of these parameters (but not necessarily)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_standard_hparams(data_path, out_dir):\n",
    "    \n",
    "    hparams = tf.contrib.training.HParams(\n",
    "        \n",
    "        # Data\n",
    "        src=\"vi\",\n",
    "        tgt=\"en\",\n",
    "        train_prefix=os.path.join(data_path, \"train\"),\n",
    "        dev_prefix=os.path.join(data_path, \"tst2012\"),\n",
    "        test_prefix=os.path.join(data_path, \"tst2013\"),\n",
    "        vocab_prefix=\"\",\n",
    "        embed_prefix=\"\",\n",
    "        out_dir=out_dir,\n",
    "        src_vocab_file=os.path.join(data_path, \"vocab.vi\"),\n",
    "        tgt_vocab_file=os.path.join(data_path, \"vocab.en\"),\n",
    "        src_embed_file=\"\",\n",
    "        tgt_embed_file=\"\",\n",
    "        src_file=os.path.join(data_path, \"train.vi\"),\n",
    "        tgt_file=os.path.join(data_path, \"train.en\"),\n",
    "        dev_src_file=os.path.join(data_path, \"tst2012.vi\"),\n",
    "        dev_tgt_file=os.path.join(data_path, \"tst2012.en\"),\n",
    "        test_src_file=os.path.join(data_path, \"tst2013.vi\"),\n",
    "        test_tgt_file=os.path.join(data_path, \"tst2013.en\"),\n",
    "\n",
    "        # Networks\n",
    "        num_units=512,\n",
    "        num_layers=1,\n",
    "        num_encoder_layers=1,\n",
    "        num_decoder_layers=1,\n",
    "        num_encoder_residual_layers=0,\n",
    "        num_decoder_residual_layers=0,\n",
    "        dropout=0.2,\n",
    "        unit_type=\"lstm\",\n",
    "        encoder_type=\"uni\",\n",
    "        residual=False,\n",
    "        time_major=True,\n",
    "        num_embeddings_partitions=0,\n",
    "\n",
    "        # Train\n",
    "        optimizer=\"adam\",\n",
    "        batch_size=128,\n",
    "        init_op=\"uniform\",\n",
    "        init_weight=0.1,\n",
    "        max_gradient_norm=100.0,\n",
    "        learning_rate=0.001,\n",
    "        warmup_steps=0,\n",
    "        warmup_scheme=\"t2t\",\n",
    "        decay_scheme=\"luong234\",\n",
    "        colocate_gradients_with_ops=True,\n",
    "        num_train_steps=4000,\n",
    "\n",
    "        # Data constraints\n",
    "        num_buckets=5,\n",
    "        max_train=0,\n",
    "        src_max_len=25,\n",
    "        tgt_max_len=25,\n",
    "        src_max_len_infer=0,\n",
    "        tgt_max_len_infer=0,\n",
    "\n",
    "        # Data format\n",
    "        sos=\"<s>\",\n",
    "        eos=\"</s>\",\n",
    "        subword_option=\"\",\n",
    "        check_special_token=True,\n",
    "\n",
    "        # Misc\n",
    "        forget_bias=1.0,\n",
    "        num_gpus=1,\n",
    "        epoch_step=0,  # record where we were within an epoch.\n",
    "        steps_per_stats=100,\n",
    "        steps_per_external_eval=0,\n",
    "        share_vocab=False,\n",
    "        metrics=[\"bleu\"],\n",
    "        log_device_placement=False,\n",
    "        random_seed=None,\n",
    "        # only enable beam search during inference when beam_width > 0.\n",
    "        beam_width=0,\n",
    "        length_penalty_weight=0.0,\n",
    "        override_loaded_hparams=True,\n",
    "        num_keep_ckpts=5,\n",
    "        avg_ckpts=False,\n",
    "        num_intra_threads=0,\n",
    "        num_inter_threads=0,\n",
    "\n",
    "        # For inference\n",
    "        inference_indices=None,\n",
    "        infer_batch_size=32,\n",
    "        sampling_temperature=0.0,\n",
    "        num_translations_per_input=1,\n",
    "        \n",
    "    )\n",
    "    \n",
    "    src_vocab_size, _ = vocab_utils.check_vocab(hparams.src_vocab_file, hparams.out_dir)\n",
    "    tgt_vocab_size, _ = vocab_utils.check_vocab(hparams.tgt_vocab_file, hparams.out_dir)\n",
    "    hparams.add_hparam('src_vocab_size', src_vocab_size)\n",
    "    hparams.add_hparam('tgt_vocab_size', tgt_vocab_size)\n",
    "    \n",
    "    out_dir = hparams.out_dir\n",
    "    if not tf.gfile.Exists(out_dir):\n",
    "        tf.gfile.MakeDirs(out_dir)\n",
    "         \n",
    "    for metric in hparams.metrics:\n",
    "        hparams.add_hparam(\"best_\" + metric, 0)  # larger is better\n",
    "        best_metric_dir = os.path.join(hparams.out_dir, \"best_\" + metric)\n",
    "        hparams.add_hparam(\"best_\" + metric + \"_dir\", best_metric_dir)\n",
    "        tf.gfile.MakeDirs(best_metric_dir)\n",
    "\n",
    "        if hparams.avg_ckpts:\n",
    "            hparams.add_hparam(\"avg_best_\" + metric, 0)  # larger is better\n",
    "            best_metric_dir = os.path.join(hparams.out_dir, \"avg_best_\" + metric)\n",
    "            hparams.add_hparam(\"avg_best_\" + metric + \"_dir\", best_metric_dir)\n",
    "            tf.gfile.MakeDirs(best_metric_dir)\n",
    "\n",
    "    return hparams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3. Training (8 pts)\n",
    "\n",
    "For this question, **train at least two of the models that use the attention modules you defined above**. Did you notice any difference in the training or evaluation of the different models? **Provide a brief written answer below.**\n",
    "\n",
    "*Note*: Make sure you **remove the model checkpoints** in the appropriate folders (`nmt_model_dotprod_att`, `nmt_model_binlinear_att` or `nmt_model_feedforward_att`)  if you would like to start training from scratch. (It's safe to delete all the files saved in the directory, or move them elsewhere.) Otherwise, the saved parameters will automatically be reloaded from the latest checkpoint and training will resume where it left off."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your written answer here!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Vocab file datasets/nmt_data_vi/vocab.vi exists\n",
      "# Vocab file datasets/nmt_data_vi/vocab.en exists\n",
      "# creating train graph ...\n",
      "  num_layers = 1, num_residual_layers=0\n",
      "  cell 0  LSTM, forget_bias=1  DropoutWrapper, dropout=0.2   DeviceWrapper, device=/gpu:0\n",
      "  cell 0512\n",
      "  DropoutWrapper, dropout=0.2   DropoutWrapper  DeviceWrapper, device=/gpu:0\n",
      "  learning_rate=0.001, warmup_steps=0, warmup_scheme=t2t\n",
      "  decay_scheme=luong234, start_decay_step=2666, decay_steps 333, decay_factor 0.5\n",
      "# Trainable variables\n",
      "  embeddings/encoder/embedding_encoder:0, (7709, 512), /device:GPU:0\n",
      "  embeddings/decoder/embedding_decoder:0, (17191, 512), /device:GPU:0\n",
      "  dynamic_seq2seq/encoder/rnn/basic_lstm_cell/kernel:0, (1024, 2048), /device:GPU:0\n",
      "  dynamic_seq2seq/encoder/rnn/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/lstm_cell_with_dummy_attention/kernel:0, (1024, 2048), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/lstm_cell_with_dummy_attention/bias:0, (2048,), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/output_projection/kernel:0, (512, 17191), \n",
      "# creating eval graph ...\n",
      "  num_layers = 1, num_residual_layers=0\n",
      "  cell 0  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\n",
      "  cell 0512\n",
      "  LSTMCellWithDummyAttention, dropout=0   LSTMCellWithDummyAttention  DeviceWrapper, device=/gpu:0\n",
      "# Trainable variables\n",
      "  embeddings/encoder/embedding_encoder:0, (7709, 512), /device:GPU:0\n",
      "  embeddings/decoder/embedding_decoder:0, (17191, 512), /device:GPU:0\n",
      "  dynamic_seq2seq/encoder/rnn/basic_lstm_cell/kernel:0, (1024, 2048), /device:GPU:0\n",
      "  dynamic_seq2seq/encoder/rnn/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/lstm_cell_with_dummy_attention/kernel:0, (1024, 2048), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/lstm_cell_with_dummy_attention/bias:0, (2048,), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/output_projection/kernel:0, (512, 17191), \n",
      "# creating infer graph ...\n",
      "  num_layers = 1, num_residual_layers=0\n",
      "  cell 0  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\n",
      "  cell 0512\n",
      "  LSTMCellWithDummyAttention, dropout=0   LSTMCellWithDummyAttention  DeviceWrapper, device=/gpu:0\n",
      "# Trainable variables\n",
      "  embeddings/encoder/embedding_encoder:0, (7709, 512), /device:GPU:0\n",
      "  embeddings/decoder/embedding_decoder:0, (17191, 512), /device:GPU:0\n",
      "  dynamic_seq2seq/encoder/rnn/basic_lstm_cell/kernel:0, (1024, 2048), /device:GPU:0\n",
      "  dynamic_seq2seq/encoder/rnn/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/lstm_cell_with_dummy_attention/kernel:0, (1024, 2048), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/lstm_cell_with_dummy_attention/bias:0, (2048,), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/output_projection/kernel:0, (512, 17191), \n",
      "INFO:tensorflow:Restoring parameters from nmt_model_noatt/translate.ckpt-1000\n",
      "  loaded train model parameters from nmt_model_noatt/translate.ckpt-1000, time 0.59s\n",
      "INFO:tensorflow:Restoring parameters from nmt_model_noatt/translate.ckpt-1000\n",
      "  loaded infer model parameters from nmt_model_noatt/translate.ckpt-1000, time 0.11s\n",
      "  # 111\n",
      "    src: Có ai muốn con của họ phải trải qua con thuyền ấy ?\n",
      "    ref: Who could ever wish it on their own ?\n",
      "    nmt: How you we to to the the of of ? ?\n",
      "INFO:tensorflow:Restoring parameters from nmt_model_noatt/translate.ckpt-1000\n",
      "  loaded eval model parameters from nmt_model_noatt/translate.ckpt-1000, time 0.12s\n",
      "  eval dev: perplexity 142.25, time 0s, Fri Apr  6 04:42:47 2018.\n",
      "  eval test: perplexity 167.18, time 0s, Fri Apr  6 04:42:47 2018.\n",
      "INFO:tensorflow:Restoring parameters from nmt_model_noatt/translate.ckpt-1000\n",
      "  loaded infer model parameters from nmt_model_noatt/translate.ckpt-1000, time 0.07s\n",
      "# External evaluation, global step 1000\n",
      "  decoding to output nmt_model_noatt/output_dev.\n",
      "  done, num sentences 1553, num translations per input 1, time 5s, Fri Apr  6 04:42:53 2018.\n",
      "  bleu dev: 1.7\n",
      "  saving hparams to nmt_model_noatt/hparams\n",
      "# External evaluation, global step 1000\n",
      "  decoding to output nmt_model_noatt/output_test.\n",
      "  done, num sentences 1268, num translations per input 1, time 5s, Fri Apr  6 04:43:02 2018.\n",
      "  bleu test: 1.1\n",
      "  saving hparams to nmt_model_noatt/hparams\n",
      "# Start step 1000, lr 0.001, Fri Apr  6 04:43:02 2018\n",
      "# Init train iterator, skipping 0 elements\n",
      "  step 1100 lr 0.001 step-time 0.21s wps 21.62K ppl 131.04 gN 6.04 bleu 1.72, Fri Apr  6 04:43:24 2018\n",
      "  step 1200 lr 0.001 step-time 0.09s wps 50.00K ppl 127.52 gN 6.27 bleu 1.72, Fri Apr  6 04:43:33 2018\n",
      "  step 1300 lr 0.001 step-time 0.08s wps 54.63K ppl 122.39 gN 6.05 bleu 1.72, Fri Apr  6 04:43:41 2018\n",
      "  step 1400 lr 0.001 step-time 0.08s wps 54.75K ppl 116.80 gN 6.05 bleu 1.72, Fri Apr  6 04:43:50 2018\n",
      "  step 1500 lr 0.001 step-time 0.08s wps 54.69K ppl 113.44 gN 5.99 bleu 1.72, Fri Apr  6 04:43:58 2018\n",
      "  step 1600 lr 0.001 step-time 0.08s wps 54.74K ppl 108.05 gN 6.15 bleu 1.72, Fri Apr  6 04:44:07 2018\n",
      "  step 1700 lr 0.001 step-time 0.08s wps 54.52K ppl 103.97 gN 5.86 bleu 1.72, Fri Apr  6 04:44:15 2018\n",
      "  step 1800 lr 0.001 step-time 0.08s wps 54.47K ppl 100.88 gN 5.75 bleu 1.72, Fri Apr  6 04:44:23 2018\n",
      "  step 1900 lr 0.001 step-time 0.08s wps 54.72K ppl 97.01 gN 5.78 bleu 1.72, Fri Apr  6 04:44:32 2018\n",
      "  step 2000 lr 0.001 step-time 0.09s wps 50.04K ppl 95.42 gN 5.87 bleu 1.72, Fri Apr  6 04:44:41 2018\n",
      "# Save eval, global step 2000\n",
      "INFO:tensorflow:Restoring parameters from nmt_model_noatt/translate.ckpt-2000\n",
      "  loaded infer model parameters from nmt_model_noatt/translate.ckpt-2000, time 0.08s\n",
      "  # 548\n",
      "    src: Và điều chúng ta thấy được là liệu số lượng nguồn tài trợ có sẵn trong kế hoạch tiết kiệm hưu trí kê hoạch số 401 có ảnh hưởng tới khả năng có thể để tiết kiệm hơn cho ngày mai\n",
      "    ref: And what we looked at was whether the number of fund offerings available in a retirement savings plan , the 401 plan , does that affect people &apos;s likelihood to save more for tomorrow .\n",
      "    nmt: And what we &apos;re is is that the the of of is that to can the the of of that that that the the of of is is to to the the of of that that , to the the that of of\n",
      "INFO:tensorflow:Restoring parameters from nmt_model_noatt/translate.ckpt-2000\n",
      "  loaded eval model parameters from nmt_model_noatt/translate.ckpt-2000, time 0.08s\n",
      "  eval dev: perplexity 99.37, time 0s, Fri Apr  6 04:44:43 2018.\n",
      "  eval test: perplexity 115.37, time 0s, Fri Apr  6 04:44:44 2018.\n",
      "# Finished an epoch, step 2043. Perform external evaluation\n",
      "INFO:tensorflow:Restoring parameters from nmt_model_noatt/translate.ckpt-2000\n",
      "  loaded infer model parameters from nmt_model_noatt/translate.ckpt-2000, time 0.08s\n",
      "  # 1331\n",
      "    src: Mặt khác , nó còn được sử dụng để kéo mọi người ra khỏi ghế ngồi mà cùng nhau tham gia một số trò chơi nhằm kiểm soát tốt hơn sức khoẻ của mình .\n",
      "    ref: But on the other hand , it also could be used to get people from out of their chairs and try to work together in some kind of gaming activity to get more control of their health .\n",
      "    nmt: The other is is the the that that the the has has to to the the , of the , , of the , , have the to of people people to to the the of of people that\n",
      "INFO:tensorflow:Restoring parameters from nmt_model_noatt/translate.ckpt-2000\n",
      "  loaded infer model parameters from nmt_model_noatt/translate.ckpt-2000, time 0.07s\n",
      "# External evaluation, global step 2000\n",
      "  decoding to output nmt_model_noatt/output_dev.\n",
      "  done, num sentences 1553, num translations per input 1, time 6s, Fri Apr  6 04:44:55 2018.\n",
      "  bleu dev: 2.7\n",
      "  saving hparams to nmt_model_noatt/hparams\n",
      "# External evaluation, global step 2000\n",
      "  decoding to output nmt_model_noatt/output_test.\n",
      "  done, num sentences 1268, num translations per input 1, time 6s, Fri Apr  6 04:45:01 2018.\n",
      "  bleu test: 1.8\n",
      "  saving hparams to nmt_model_noatt/hparams\n",
      "  step 2100 lr 0.001 step-time 0.23s wps 19.44K ppl 81.86 gN 6.06 bleu 2.74, Fri Apr  6 04:45:21 2018\n",
      "  step 2200 lr 0.001 step-time 0.11s wps 43.07K ppl 76.56 gN 6.12 bleu 2.74, Fri Apr  6 04:45:31 2018\n",
      "  step 2300 lr 0.001 step-time 0.09s wps 48.96K ppl 75.74 gN 6.25 bleu 2.74, Fri Apr  6 04:45:41 2018\n",
      "  step 2400 lr 0.001 step-time 0.09s wps 49.08K ppl 75.54 gN 6.42 bleu 2.74, Fri Apr  6 04:45:50 2018\n",
      "  step 2500 lr 0.001 step-time 0.09s wps 48.75K ppl 74.26 gN 6.12 bleu 2.74, Fri Apr  6 04:46:00 2018\n",
      "  step 2600 lr 0.001 step-time 0.09s wps 49.00K ppl 73.44 gN 6.20 bleu 2.74, Fri Apr  6 04:46:09 2018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  step 2700 lr 0.001 step-time 0.09s wps 48.59K ppl 70.29 gN 6.00 bleu 2.74, Fri Apr  6 04:46:19 2018\n",
      "  step 2800 lr 0.001 step-time 0.09s wps 49.07K ppl 70.76 gN 6.13 bleu 2.74, Fri Apr  6 04:46:28 2018\n",
      "  step 2900 lr 0.001 step-time 0.09s wps 49.18K ppl 68.19 gN 6.12 bleu 2.74, Fri Apr  6 04:46:37 2018\n",
      "  step 3000 lr 0.0005 step-time 0.08s wps 55.19K ppl 68.42 gN 6.00 bleu 2.74, Fri Apr  6 04:46:46 2018\n",
      "# Save eval, global step 3000\n",
      "INFO:tensorflow:Restoring parameters from nmt_model_noatt/translate.ckpt-3000\n",
      "  loaded infer model parameters from nmt_model_noatt/translate.ckpt-3000, time 0.08s\n",
      "  # 169\n",
      "    src: cuối cùng bà nói &quot; điều thứ 3 là con hãy hứa với bà rằng con sẽ không bao giờ uống rượu &quot; .\n",
      "    ref: Then finally she said , &quot; The third thing I want you to promise me is that you &apos;ll never drink alcohol . &quot;\n",
      "    nmt: The finally said she &quot; , , <unk> &apos;s , , &apos;s &apos;s to to . . &apos;s\n",
      "INFO:tensorflow:Restoring parameters from nmt_model_noatt/translate.ckpt-3000\n",
      "  loaded eval model parameters from nmt_model_noatt/translate.ckpt-3000, time 0.08s\n",
      "  eval dev: perplexity 82.39, time 0s, Fri Apr  6 04:46:47 2018.\n",
      "  eval test: perplexity 95.87, time 0s, Fri Apr  6 04:46:48 2018.\n",
      "# Finished an epoch, step 3086. Perform external evaluation\n",
      "INFO:tensorflow:Restoring parameters from nmt_model_noatt/translate.ckpt-3000\n",
      "  loaded infer model parameters from nmt_model_noatt/translate.ckpt-3000, time 0.07s\n",
      "  # 630\n",
      "    src: Và những lựa chọn đó làm thay đổi 1 lượng sự lựa chọn mà họ đưa ra mỗi quyết định .\n",
      "    ref: Now these decisions vary in the number of choices that they offer per decision .\n",
      "    nmt: And the the that that that to to is the to that the to of that that to need the do of need need do do .\n",
      "INFO:tensorflow:Restoring parameters from nmt_model_noatt/translate.ckpt-3000\n",
      "  loaded infer model parameters from nmt_model_noatt/translate.ckpt-3000, time 0.07s\n",
      "# External evaluation, global step 3000\n",
      "  decoding to output nmt_model_noatt/output_dev.\n",
      "  done, num sentences 1553, num translations per input 1, time 6s, Fri Apr  6 04:47:01 2018.\n",
      "  bleu dev: 3.2\n",
      "  saving hparams to nmt_model_noatt/hparams\n",
      "# External evaluation, global step 3000\n",
      "  decoding to output nmt_model_noatt/output_test.\n",
      "  done, num sentences 1268, num translations per input 1, time 5s, Fri Apr  6 04:47:08 2018.\n",
      "  bleu test: 2.2\n",
      "  saving hparams to nmt_model_noatt/hparams\n",
      "  step 3100 lr 0.0005 step-time 0.19s wps 23.24K ppl 62.68 gN 5.88 bleu 3.18, Fri Apr  6 04:47:20 2018\n",
      "  step 3200 lr 0.0005 step-time 0.10s wps 44.47K ppl 51.79 gN 6.20 bleu 3.18, Fri Apr  6 04:47:31 2018\n",
      "  step 3300 lr 0.0005 step-time 0.09s wps 51.26K ppl 51.67 gN 6.32 bleu 3.18, Fri Apr  6 04:47:40 2018\n",
      "  step 3400 lr 0.00025 step-time 0.08s wps 55.08K ppl 51.19 gN 6.24 bleu 3.18, Fri Apr  6 04:47:48 2018\n",
      "  step 3500 lr 0.00025 step-time 0.08s wps 55.04K ppl 50.10 gN 6.35 bleu 3.18, Fri Apr  6 04:47:56 2018\n",
      "  step 3600 lr 0.00025 step-time 0.08s wps 54.60K ppl 49.69 gN 6.22 bleu 3.18, Fri Apr  6 04:48:05 2018\n",
      "  step 3700 lr 0.000125 step-time 0.08s wps 55.12K ppl 51.52 gN 6.43 bleu 3.18, Fri Apr  6 04:48:13 2018\n",
      "  step 3800 lr 0.000125 step-time 0.08s wps 54.84K ppl 49.27 gN 6.29 bleu 3.18, Fri Apr  6 04:48:22 2018\n",
      "  step 3900 lr 0.000125 step-time 0.08s wps 54.95K ppl 50.00 gN 6.31 bleu 3.18, Fri Apr  6 04:48:30 2018\n",
      "  step 4000 lr 6.25e-05 step-time 0.08s wps 55.19K ppl 49.93 gN 6.40 bleu 3.18, Fri Apr  6 04:48:38 2018\n",
      "# Save eval, global step 4000\n",
      "INFO:tensorflow:Restoring parameters from nmt_model_noatt/translate.ckpt-4000\n",
      "  loaded infer model parameters from nmt_model_noatt/translate.ckpt-4000, time 0.08s\n",
      "  # 563\n",
      "    src: cho nên điều tôi muốn đề nghị bạn hôm nay là 4 kĩ thuật đơn giản Những kĩ thuật mà chúng tôi đã kiểm tra bằng nhiều cách trong nhiều bản khảo sát mà bạn có thể áp dụng dễ dàng trong kinh doanh của bạn\n",
      "    ref: So what I want to propose to you today are four simple techniques -- techniques that we have tested in one way or another in different research venues -- that you can easily apply in your businesses .\n",
      "    nmt: So what I want to to you today is is the a of of that that , can you the the of of that that , can the the that of of , that , can , the the that of of , , , ,\n",
      "INFO:tensorflow:Restoring parameters from nmt_model_noatt/translate.ckpt-4000\n",
      "  loaded eval model parameters from nmt_model_noatt/translate.ckpt-4000, time 0.08s\n",
      "  eval dev: perplexity 77.41, time 0s, Fri Apr  6 04:48:40 2018.\n",
      "  eval test: perplexity 90.53, time 0s, Fri Apr  6 04:48:40 2018.\n",
      "INFO:tensorflow:Restoring parameters from nmt_model_noatt/translate.ckpt-4000\n",
      "  loaded infer model parameters from nmt_model_noatt/translate.ckpt-4000, time 0.08s\n",
      "  # 831\n",
      "    src: Với những điều đó , sai lầm là bất khả kháng .\n",
      "    ref: Given all of that , mistakes are inevitable .\n",
      "    nmt: And that , , , , , &apos;s &apos;s , . &apos;s &apos;s . . &apos;s &apos;s . .\n",
      "INFO:tensorflow:Restoring parameters from nmt_model_noatt/translate.ckpt-4000\n",
      "  loaded eval model parameters from nmt_model_noatt/translate.ckpt-4000, time 0.08s\n",
      "  eval dev: perplexity 77.41, time 0s, Fri Apr  6 04:48:47 2018.\n",
      "  eval test: perplexity 90.53, time 0s, Fri Apr  6 04:48:48 2018.\n",
      "INFO:tensorflow:Restoring parameters from nmt_model_noatt/translate.ckpt-4000\n",
      "  loaded infer model parameters from nmt_model_noatt/translate.ckpt-4000, time 0.08s\n",
      "# External evaluation, global step 4000\n",
      "  decoding to output nmt_model_noatt/output_dev.\n",
      "  done, num sentences 1553, num translations per input 1, time 5s, Fri Apr  6 04:48:54 2018.\n",
      "  bleu dev: 3.4\n",
      "  saving hparams to nmt_model_noatt/hparams\n",
      "# External evaluation, global step 4000\n",
      "  decoding to output nmt_model_noatt/output_test.\n",
      "  done, num sentences 1268, num translations per input 1, time 5s, Fri Apr  6 04:49:00 2018.\n",
      "  bleu test: 2.6\n",
      "  saving hparams to nmt_model_noatt/hparams\n",
      "# Final, step 4000 lr 6.25e-05 step-time 0.08s wps 55.19K ppl 49.93 gN 6.40 dev ppl 77.41, dev bleu 3.4, test ppl 90.53, test bleu 2.6, Fri Apr  6 04:49:00 2018\n",
      "# Done training!, time 358s, Fri Apr  6 04:49:00 2018.\n",
      "# Start evaluating saved best models.\n",
      "INFO:tensorflow:Restoring parameters from nmt_model_noatt/best_bleu/translate.ckpt-4000\n",
      "  loaded infer model parameters from nmt_model_noatt/best_bleu/translate.ckpt-4000, time 0.08s\n",
      "  # 1135\n",
      "    src: Một phương pháp đặc biệt thú vị mà tôi hiện vẫn đang dùng nhiều là bản thân sự tiến hoá\n",
      "    ref: One method that &apos;s particularly interesting that I &apos;ve been using a lot lately is evolution itself .\n",
      "    nmt: The the of of that that that &apos;m me is that that is have the lot that the to that that of\n",
      "INFO:tensorflow:Restoring parameters from nmt_model_noatt/best_bleu/translate.ckpt-4000\n",
      "  loaded eval model parameters from nmt_model_noatt/best_bleu/translate.ckpt-4000, time 0.08s\n",
      "  eval dev: perplexity 77.41, time 0s, Fri Apr  6 04:49:01 2018.\n",
      "  eval test: perplexity 90.53, time 0s, Fri Apr  6 04:49:02 2018.\n",
      "INFO:tensorflow:Restoring parameters from nmt_model_noatt/best_bleu/translate.ckpt-4000\n",
      "  loaded infer model parameters from nmt_model_noatt/best_bleu/translate.ckpt-4000, time 0.08s\n",
      "# External evaluation, global step 4000\n",
      "  decoding to output nmt_model_noatt/output_dev.\n",
      "  done, num sentences 1553, num translations per input 1, time 5s, Fri Apr  6 04:49:08 2018.\n",
      "  bleu dev: 3.4\n",
      "  saving hparams to nmt_model_noatt/hparams\n",
      "# External evaluation, global step 4000\n",
      "  decoding to output nmt_model_noatt/output_test.\n",
      "  done, num sentences 1268, num translations per input 1, time 5s, Fri Apr  6 04:49:14 2018.\n",
      "  bleu test: 2.6\n",
      "  saving hparams to nmt_model_noatt/hparams\n",
      "# Best bleu, step 4000 lr 6.25e-05 step-time 0.08s wps 55.19K ppl 49.93 gN 6.40 dev ppl 77.41, dev bleu 3.4, test ppl 90.53, test bleu 2.6, Fri Apr  6 04:49:14 2018\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'dev_ppl': 77.41107273553719,\n",
       "  'dev_scores': {'bleu': 3.416317859377748},\n",
       "  'test_ppl': 90.53395809449005,\n",
       "  'test_scores': {'bleu': 2.6233721337966576}},\n",
       " 4000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If desired as a baseline, train a vanilla LSTM model without attention\n",
    "hparams = create_standard_hparams(\n",
    "    data_path=os.path.join(\"datasets\", \"nmt_data_vi\"), \n",
    "    out_dir=\"nmt_model_noatt\"\n",
    ")\n",
    "hparams.add_hparam(\"attention_cell_class\", LSTMCellWithDummyAttention)\n",
    "train(hparams, AttentionalModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Vocab file datasets/nmt_data_vi/vocab.vi exists\n",
      "# Vocab file datasets/nmt_data_vi/vocab.en exists\n",
      "# creating train graph ...\n",
      "  num_layers = 1, num_residual_layers=0\n",
      "  cell 0  LSTM, forget_bias=1  DropoutWrapper, dropout=0.2   DeviceWrapper, device=/gpu:0\n",
      "  cell 0512\n",
      "  DropoutWrapper, dropout=0.2   DropoutWrapper  DeviceWrapper, device=/gpu:0\n",
      "WARNING:tensorflow:From <ipython-input-5-f0d6906f20ef>:16: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From <ipython-input-5-f0d6906f20ef>:17: calling reduce_max (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "  learning_rate=0.001, warmup_steps=0, warmup_scheme=t2t\n",
      "  decay_scheme=luong234, start_decay_step=2666, decay_steps 333, decay_factor 0.5\n",
      "# Trainable variables\n",
      "  embeddings/encoder/embedding_encoder:0, (7709, 512), /device:GPU:0\n",
      "  embeddings/decoder/embedding_decoder:0, (17191, 512), /device:GPU:0\n",
      "  dynamic_seq2seq/encoder/rnn/basic_lstm_cell/kernel:0, (1024, 2048), /device:GPU:0\n",
      "  dynamic_seq2seq/encoder/rnn/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/lstm_cell_with_dot_product_attention/kernel:0, (1024, 2048), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/lstm_cell_with_dot_product_attention/bias:0, (2048,), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/lstm_cell_with_dot_product_attention/W_c:0, (1024, 256), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/output_projection/kernel:0, (256, 17191), \n",
      "# creating eval graph ...\n",
      "  num_layers = 1, num_residual_layers=0\n",
      "  cell 0  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\n",
      "  cell 0512\n",
      "  LSTMCellWithDotProductAttention, dropout=0   LSTMCellWithDotProductAttention  DeviceWrapper, device=/gpu:0\n",
      "# Trainable variables\n",
      "  embeddings/encoder/embedding_encoder:0, (7709, 512), /device:GPU:0\n",
      "  embeddings/decoder/embedding_decoder:0, (17191, 512), /device:GPU:0\n",
      "  dynamic_seq2seq/encoder/rnn/basic_lstm_cell/kernel:0, (1024, 2048), /device:GPU:0\n",
      "  dynamic_seq2seq/encoder/rnn/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/lstm_cell_with_dot_product_attention/kernel:0, (1024, 2048), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/lstm_cell_with_dot_product_attention/bias:0, (2048,), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/lstm_cell_with_dot_product_attention/W_c:0, (1024, 256), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/output_projection/kernel:0, (256, 17191), \n",
      "# creating infer graph ...\n",
      "  num_layers = 1, num_residual_layers=0\n",
      "  cell 0  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\n",
      "  cell 0512\n",
      "  LSTMCellWithDotProductAttention, dropout=0   LSTMCellWithDotProductAttention  DeviceWrapper, device=/gpu:0\n",
      "# Trainable variables\n",
      "  embeddings/encoder/embedding_encoder:0, (7709, 512), /device:GPU:0\n",
      "  embeddings/decoder/embedding_decoder:0, (17191, 512), /device:GPU:0\n",
      "  dynamic_seq2seq/encoder/rnn/basic_lstm_cell/kernel:0, (1024, 2048), /device:GPU:0\n",
      "  dynamic_seq2seq/encoder/rnn/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/lstm_cell_with_dot_product_attention/kernel:0, (1024, 2048), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/lstm_cell_with_dot_product_attention/bias:0, (2048,), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/lstm_cell_with_dot_product_attention/W_c:0, (1024, 256), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/output_projection/kernel:0, (256, 17191), \n",
      "  created train model with fresh parameters, time 0.32s\n",
      "  created infer model with fresh parameters, time 0.07s\n",
      "  # 1127\n",
      "    src: Và tôi nghĩ rằng đó là thứ mà chúng ta đang thấy ở đây , trong sự bùng nổ của đường cong này .\n",
      "    ref: And I think that that &apos;s what we &apos;re seeing here in this explosion of curve .\n",
      "    nmt: visualizing implicated prototype prototype qualifications qualifications collagen collagen collagen buried buried buried buried drowned swimming tapping drowned drowned altering altering altering altering altering Fine Fine virtuoso monk Luther Luther enabled enabled enabled enabled enabled enabled enabled equipment secured thread peer secured secured peer peer peer peer peer intellectuals\n",
      "  created eval model with fresh parameters, time 0.09s\n",
      "  eval dev: perplexity 17244.04, time 0s, Fri Apr  6 04:49:18 2018.\n",
      "  eval test: perplexity 17298.74, time 0s, Fri Apr  6 04:49:19 2018.\n",
      "  created infer model with fresh parameters, time 0.05s\n",
      "# Start step 0, lr 0.001, Fri Apr  6 04:49:19 2018\n",
      "# Init train iterator, skipping 0 elements\n",
      "  step 100 lr 0.001 step-time 0.25s wps 18.91K ppl 600.81 gN 14.32 bleu 0.00, Fri Apr  6 04:49:44 2018\n",
      "  step 200 lr 0.001 step-time 0.10s wps 44.29K ppl 365.36 gN 10.69 bleu 0.00, Fri Apr  6 04:49:54 2018\n",
      "  step 300 lr 0.001 step-time 0.10s wps 46.47K ppl 321.90 gN 9.25 bleu 0.00, Fri Apr  6 04:50:04 2018\n",
      "  step 400 lr 0.001 step-time 0.10s wps 46.61K ppl 267.30 gN 9.02 bleu 0.00, Fri Apr  6 04:50:14 2018\n",
      "  step 500 lr 0.001 step-time 0.10s wps 46.38K ppl 228.68 gN 9.40 bleu 0.00, Fri Apr  6 04:50:24 2018\n",
      "  step 600 lr 0.001 step-time 0.10s wps 46.57K ppl 205.01 gN 8.33 bleu 0.00, Fri Apr  6 04:50:34 2018\n",
      "  step 700 lr 0.001 step-time 0.10s wps 46.48K ppl 182.12 gN 7.85 bleu 0.00, Fri Apr  6 04:50:44 2018\n",
      "  step 800 lr 0.001 step-time 0.10s wps 46.89K ppl 163.18 gN 7.38 bleu 0.00, Fri Apr  6 04:50:54 2018\n",
      "  step 900 lr 0.001 step-time 0.10s wps 46.24K ppl 151.08 gN 6.99 bleu 0.00, Fri Apr  6 04:51:04 2018\n",
      "  step 1000 lr 0.001 step-time 0.10s wps 46.71K ppl 139.31 gN 7.20 bleu 0.00, Fri Apr  6 04:51:14 2018\n",
      "# Save eval, global step 1000\n",
      "INFO:tensorflow:Restoring parameters from nmt_model_dotprodatt/translate.ckpt-1000\n",
      "  loaded infer model parameters from nmt_model_dotprodatt/translate.ckpt-1000, time 0.07s\n",
      "  # 153\n",
      "    src: tôi nhớ như in ngày đó , tưởng chừng như mới xảy qua hôm qua vậy\n",
      "    ref: And I remember this just like it happened yesterday .\n",
      "    nmt: I I , , , the the of of , is was the in of . .\n",
      "INFO:tensorflow:Restoring parameters from nmt_model_dotprodatt/translate.ckpt-1000\n",
      "  loaded eval model parameters from nmt_model_dotprodatt/translate.ckpt-1000, time 0.08s\n",
      "  eval dev: perplexity 132.01, time 0s, Fri Apr  6 04:51:15 2018.\n",
      "  eval test: perplexity 155.39, time 0s, Fri Apr  6 04:51:16 2018.\n",
      "# Finished an epoch, step 1043. Perform external evaluation\n",
      "INFO:tensorflow:Restoring parameters from nmt_model_dotprodatt/translate.ckpt-1000\n",
      "  loaded infer model parameters from nmt_model_dotprodatt/translate.ckpt-1000, time 0.07s\n",
      "  # 1097\n",
      "    src: Và trên thực tế , chúng được phân hoá trong quần thể và những cấu trúc đặc biệt chịu trách nhiệm cho việc ghi chép , đọc hiểu , xử lí thông tin .\n",
      "    ref: And in fact , they began to get specialists in the community and special structures that were responsible for recording , understanding , learning information .\n",
      "    nmt: And , , we we the the of of of , , the the of of is is the the of of , and the the of of is is , to we\n",
      "INFO:tensorflow:Restoring parameters from nmt_model_dotprodatt/translate.ckpt-1000\n",
      "  loaded infer model parameters from nmt_model_dotprodatt/translate.ckpt-1000, time 0.07s\n",
      "# External evaluation, global step 1000\n",
      "  decoding to output nmt_model_dotprodatt/output_dev.\n",
      "  done, num sentences 1553, num translations per input 1, time 7s, Fri Apr  6 04:51:27 2018.\n",
      "  bleu dev: 1.7\n",
      "  saving hparams to nmt_model_dotprodatt/hparams\n",
      "# External evaluation, global step 1000\n",
      "  decoding to output nmt_model_dotprodatt/output_test.\n",
      "  done, num sentences 1268, num translations per input 1, time 6s, Fri Apr  6 04:51:35 2018.\n",
      "  bleu test: 1.0\n",
      "  saving hparams to nmt_model_dotprodatt/hparams\n",
      "  step 1100 lr 0.001 step-time 0.23s wps 19.72K ppl 124.08 gN 7.16 bleu 1.67, Fri Apr  6 04:51:53 2018\n",
      "  step 1200 lr 0.001 step-time 0.12s wps 39.38K ppl 117.72 gN 7.08 bleu 1.67, Fri Apr  6 04:52:05 2018\n",
      "  step 1300 lr 0.001 step-time 0.10s wps 46.24K ppl 112.28 gN 6.90 bleu 1.67, Fri Apr  6 04:52:15 2018\n",
      "  step 1400 lr 0.001 step-time 0.11s wps 43.12K ppl 107.18 gN 6.77 bleu 1.67, Fri Apr  6 04:52:26 2018\n",
      "  step 1500 lr 0.001 step-time 0.12s wps 38.61K ppl 100.94 gN 6.90 bleu 1.67, Fri Apr  6 04:52:38 2018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  step 1600 lr 0.001 step-time 0.12s wps 38.93K ppl 98.43 gN 6.64 bleu 1.67, Fri Apr  6 04:52:50 2018\n",
      "  step 1700 lr 0.001 step-time 0.12s wps 38.75K ppl 93.98 gN 6.68 bleu 1.67, Fri Apr  6 04:53:02 2018\n",
      "  step 1800 lr 0.001 step-time 0.12s wps 38.59K ppl 91.31 gN 6.68 bleu 1.67, Fri Apr  6 04:53:14 2018\n",
      "  step 1900 lr 0.001 step-time 0.12s wps 38.70K ppl 86.43 gN 6.72 bleu 1.67, Fri Apr  6 04:53:26 2018\n",
      "  step 2000 lr 0.001 step-time 0.12s wps 38.67K ppl 82.70 gN 6.58 bleu 1.67, Fri Apr  6 04:53:37 2018\n",
      "# Save eval, global step 2000\n",
      "INFO:tensorflow:Restoring parameters from nmt_model_dotprodatt/translate.ckpt-2000\n",
      "  loaded infer model parameters from nmt_model_dotprodatt/translate.ckpt-2000, time 0.07s\n",
      "  # 385\n",
      "    src: Rằng sự tồn tại của tất cả chúng ta gắn bó mật thiết với sự tồn tài của từng người .\n",
      "    ref: That all of our survival is tied to the survival of everyone .\n",
      "    nmt: And &apos;s &apos;s our of of that that of of are are to to with with of of . . of &apos;s . .\n",
      "INFO:tensorflow:Restoring parameters from nmt_model_dotprodatt/translate.ckpt-2000\n",
      "  loaded eval model parameters from nmt_model_dotprodatt/translate.ckpt-2000, time 0.07s\n",
      "  eval dev: perplexity 91.48, time 1s, Fri Apr  6 04:53:39 2018.\n",
      "  eval test: perplexity 108.12, time 1s, Fri Apr  6 04:53:40 2018.\n",
      "# Finished an epoch, step 2086. Perform external evaluation\n",
      "INFO:tensorflow:Restoring parameters from nmt_model_dotprodatt/translate.ckpt-2000\n",
      "  loaded infer model parameters from nmt_model_dotprodatt/translate.ckpt-2000, time 0.07s\n",
      "  # 611\n",
      "    src: bây giờ là 2 loại nữ trang khác nhau\n",
      "    ref: Here are two different jewelry displays .\n",
      "    nmt: Now here are two two . . are are . .\n",
      "INFO:tensorflow:Restoring parameters from nmt_model_dotprodatt/translate.ckpt-2000\n",
      "  loaded infer model parameters from nmt_model_dotprodatt/translate.ckpt-2000, time 0.07s\n",
      "# External evaluation, global step 2000\n",
      "  decoding to output nmt_model_dotprodatt/output_dev.\n",
      "  done, num sentences 1553, num translations per input 1, time 8s, Fri Apr  6 04:53:59 2018.\n",
      "  bleu dev: 2.4\n",
      "  saving hparams to nmt_model_dotprodatt/hparams\n",
      "# External evaluation, global step 2000\n",
      "  decoding to output nmt_model_dotprodatt/output_test.\n",
      "  done, num sentences 1268, num translations per input 1, time 8s, Fri Apr  6 04:54:08 2018.\n",
      "  bleu test: 1.7\n",
      "  saving hparams to nmt_model_dotprodatt/hparams\n",
      "  step 2100 lr 0.001 step-time 0.23s wps 19.42K ppl 77.08 gN 6.72 bleu 2.36, Fri Apr  6 04:54:22 2018\n",
      "  step 2200 lr 0.001 step-time 0.14s wps 33.33K ppl 65.71 gN 6.81 bleu 2.36, Fri Apr  6 04:54:35 2018\n",
      "  step 2300 lr 0.001 step-time 0.12s wps 38.78K ppl 64.99 gN 7.00 bleu 2.36, Fri Apr  6 04:54:47 2018\n",
      "  step 2400 lr 0.001 step-time 0.12s wps 38.72K ppl 64.59 gN 6.79 bleu 2.36, Fri Apr  6 04:54:59 2018\n",
      "  step 2500 lr 0.001 step-time 0.12s wps 38.86K ppl 64.69 gN 6.79 bleu 2.36, Fri Apr  6 04:55:11 2018\n",
      "  step 2600 lr 0.001 step-time 0.12s wps 38.64K ppl 62.49 gN 6.56 bleu 2.36, Fri Apr  6 04:55:23 2018\n",
      "  step 2700 lr 0.001 step-time 0.12s wps 38.89K ppl 63.10 gN 7.49 bleu 2.36, Fri Apr  6 04:55:35 2018\n",
      "  step 2800 lr 0.001 step-time 0.12s wps 38.79K ppl 59.76 gN 6.44 bleu 2.36, Fri Apr  6 04:55:47 2018\n",
      "  step 2900 lr 0.001 step-time 0.12s wps 38.97K ppl 59.16 gN 6.55 bleu 2.36, Fri Apr  6 04:55:59 2018\n",
      "  step 3000 lr 0.0005 step-time 0.12s wps 38.71K ppl 57.87 gN 6.78 bleu 2.36, Fri Apr  6 04:56:10 2018\n",
      "# Save eval, global step 3000\n",
      "INFO:tensorflow:Restoring parameters from nmt_model_dotprodatt/translate.ckpt-3000\n",
      "  loaded infer model parameters from nmt_model_dotprodatt/translate.ckpt-3000, time 0.07s\n",
      "  # 1044\n",
      "    src: Vì vậy , nói cách khác , tương lai dường như chùn lại một năm mỗi năm cho cả đời người .\n",
      "    ref: So in other words , the future has kind of been shrinking one year per year for my whole lifetime .\n",
      "    nmt: So , the the , , , , , , , the the of of way , it the to way people\n",
      "INFO:tensorflow:Restoring parameters from nmt_model_dotprodatt/translate.ckpt-3000\n",
      "  loaded eval model parameters from nmt_model_dotprodatt/translate.ckpt-3000, time 0.07s\n",
      "  eval dev: perplexity 75.55, time 1s, Fri Apr  6 04:56:12 2018.\n",
      "  eval test: perplexity 89.09, time 0s, Fri Apr  6 04:56:13 2018.\n",
      "  step 3100 lr 0.0005 step-time 0.12s wps 39.01K ppl 56.96 gN 6.23 bleu 2.36, Fri Apr  6 04:56:25 2018\n",
      "# Finished an epoch, step 3129. Perform external evaluation\n",
      "INFO:tensorflow:Restoring parameters from nmt_model_dotprodatt/translate.ckpt-3000\n",
      "  loaded infer model parameters from nmt_model_dotprodatt/translate.ckpt-3000, time 0.07s\n",
      "  # 742\n",
      "    src: Và bà gần như không thở nổi và bà xanh lét .\n",
      "    ref: And she was barely breathing and she was blue .\n",
      "    nmt: And she was not , , she <unk> <unk> <unk>\n",
      "INFO:tensorflow:Restoring parameters from nmt_model_dotprodatt/translate.ckpt-3000\n",
      "  loaded infer model parameters from nmt_model_dotprodatt/translate.ckpt-3000, time 0.07s\n",
      "# External evaluation, global step 3000\n",
      "  decoding to output nmt_model_dotprodatt/output_dev.\n",
      "  done, num sentences 1553, num translations per input 1, time 9s, Fri Apr  6 04:56:38 2018.\n",
      "  bleu dev: 2.8\n",
      "  saving hparams to nmt_model_dotprodatt/hparams\n",
      "# External evaluation, global step 3000\n",
      "  decoding to output nmt_model_dotprodatt/output_test.\n",
      "  done, num sentences 1268, num translations per input 1, time 8s, Fri Apr  6 04:56:47 2018.\n",
      "  bleu test: 2.1\n",
      "  saving hparams to nmt_model_dotprodatt/hparams\n",
      "  step 3200 lr 0.0005 step-time 0.25s wps 17.78K ppl 46.13 gN 6.35 bleu 2.84, Fri Apr  6 04:57:09 2018\n",
      "  step 3300 lr 0.0005 step-time 0.13s wps 36.60K ppl 42.60 gN 6.50 bleu 2.84, Fri Apr  6 04:57:22 2018\n",
      "  step 3400 lr 0.00025 step-time 0.12s wps 38.66K ppl 42.26 gN 6.46 bleu 2.84, Fri Apr  6 04:57:33 2018\n",
      "  step 3500 lr 0.00025 step-time 0.12s wps 38.85K ppl 42.82 gN 6.54 bleu 2.84, Fri Apr  6 04:57:45 2018\n",
      "  step 3600 lr 0.00025 step-time 0.12s wps 38.62K ppl 42.32 gN 6.54 bleu 2.84, Fri Apr  6 04:57:57 2018\n",
      "  step 3700 lr 0.000125 step-time 0.12s wps 38.72K ppl 42.04 gN 6.61 bleu 2.84, Fri Apr  6 04:58:09 2018\n",
      "  step 3800 lr 0.000125 step-time 0.12s wps 38.81K ppl 41.72 gN 6.47 bleu 2.84, Fri Apr  6 04:58:21 2018\n",
      "  step 3900 lr 0.000125 step-time 0.11s wps 41.12K ppl 41.10 gN 6.51 bleu 2.84, Fri Apr  6 04:58:32 2018\n",
      "  step 4000 lr 6.25e-05 step-time 0.10s wps 46.13K ppl 41.91 gN 6.58 bleu 2.84, Fri Apr  6 04:58:42 2018\n",
      "# Save eval, global step 4000\n",
      "INFO:tensorflow:Restoring parameters from nmt_model_dotprodatt/translate.ckpt-4000\n",
      "  loaded infer model parameters from nmt_model_dotprodatt/translate.ckpt-4000, time 0.07s\n",
      "  # 447\n",
      "    src: trong những năm 70-- , à không , bắt đầu từ những năm 60-- Châu Âu thực hiện rất nhiều các dự án phát triển\n",
      "    ref: In the &apos; 70s -- well , beginning in the &apos; 60s -- Europe did lots of development projects .\n",
      "    nmt: In in , , , <unk> <unk> , ago was the the of of years ago , the <unk> of were developed developed <unk> <unk>\n",
      "INFO:tensorflow:Restoring parameters from nmt_model_dotprodatt/translate.ckpt-4000\n",
      "  loaded eval model parameters from nmt_model_dotprodatt/translate.ckpt-4000, time 0.07s\n",
      "  eval dev: perplexity 69.99, time 0s, Fri Apr  6 04:58:44 2018.\n",
      "  eval test: perplexity 82.57, time 0s, Fri Apr  6 04:58:44 2018.\n",
      "INFO:tensorflow:Restoring parameters from nmt_model_dotprodatt/translate.ckpt-4000\n",
      "  loaded infer model parameters from nmt_model_dotprodatt/translate.ckpt-4000, time 0.07s\n",
      "  # 1377\n",
      "    src: Những bức ảnh nơi mà bạn sẽ cần một chút thời gian để tư duy để tìm ra một bí quyết .\n",
      "    ref: Photos where you will need a brief moment to think to figure out the trick .\n",
      "    nmt: The these that are you you to to a a bit bit to to a a bit bit to to .\n",
      "INFO:tensorflow:Restoring parameters from nmt_model_dotprodatt/translate.ckpt-4000\n",
      "  loaded eval model parameters from nmt_model_dotprodatt/translate.ckpt-4000, time 0.07s\n",
      "  eval dev: perplexity 70.00, time 0s, Fri Apr  6 04:58:53 2018.\n",
      "  eval test: perplexity 82.57, time 0s, Fri Apr  6 04:58:54 2018.\n",
      "INFO:tensorflow:Restoring parameters from nmt_model_dotprodatt/translate.ckpt-4000\n",
      "  loaded infer model parameters from nmt_model_dotprodatt/translate.ckpt-4000, time 0.07s\n",
      "# External evaluation, global step 4000\n",
      "  decoding to output nmt_model_dotprodatt/output_dev.\n",
      "  done, num sentences 1553, num translations per input 1, time 7s, Fri Apr  6 04:59:01 2018.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  bleu dev: 3.1\n",
      "  saving hparams to nmt_model_dotprodatt/hparams\n",
      "# External evaluation, global step 4000\n",
      "  decoding to output nmt_model_dotprodatt/output_test.\n",
      "  done, num sentences 1268, num translations per input 1, time 6s, Fri Apr  6 04:59:08 2018.\n",
      "  bleu test: 2.4\n",
      "  saving hparams to nmt_model_dotprodatt/hparams\n",
      "# Final, step 4000 lr 6.25e-05 step-time 0.10s wps 46.13K ppl 41.91 gN 6.58 dev ppl 70.00, dev bleu 3.1, test ppl 82.57, test bleu 2.4, Fri Apr  6 04:59:08 2018\n",
      "# Done training!, time 589s, Fri Apr  6 04:59:08 2018.\n",
      "# Start evaluating saved best models.\n",
      "INFO:tensorflow:Restoring parameters from nmt_model_dotprodatt/best_bleu/translate.ckpt-4000\n",
      "  loaded infer model parameters from nmt_model_dotprodatt/best_bleu/translate.ckpt-4000, time 0.07s\n",
      "  # 162\n",
      "    src: rồi bà nói tiếp &quot; Con chỉ cần hứa với bà 3 điều , Bryan à &quot;\n",
      "    ref: And then she said , &quot; I just need you to promise me three things , Bryan . &quot;\n",
      "    nmt: And she said , &quot; You just just to to to , , , , , , , ,\n",
      "INFO:tensorflow:Restoring parameters from nmt_model_dotprodatt/best_bleu/translate.ckpt-4000\n",
      "  loaded eval model parameters from nmt_model_dotprodatt/best_bleu/translate.ckpt-4000, time 0.07s\n",
      "  eval dev: perplexity 70.00, time 0s, Fri Apr  6 04:59:09 2018.\n",
      "  eval test: perplexity 82.57, time 0s, Fri Apr  6 04:59:10 2018.\n",
      "INFO:tensorflow:Restoring parameters from nmt_model_dotprodatt/best_bleu/translate.ckpt-4000\n",
      "  loaded infer model parameters from nmt_model_dotprodatt/best_bleu/translate.ckpt-4000, time 0.07s\n",
      "# External evaluation, global step 4000\n",
      "  decoding to output nmt_model_dotprodatt/output_dev.\n",
      "  done, num sentences 1553, num translations per input 1, time 6s, Fri Apr  6 04:59:17 2018.\n",
      "  bleu dev: 3.1\n",
      "  saving hparams to nmt_model_dotprodatt/hparams\n",
      "# External evaluation, global step 4000\n",
      "  decoding to output nmt_model_dotprodatt/output_test.\n",
      "  done, num sentences 1268, num translations per input 1, time 6s, Fri Apr  6 04:59:24 2018.\n",
      "  bleu test: 2.4\n",
      "  saving hparams to nmt_model_dotprodatt/hparams\n",
      "# Best bleu, step 4000 lr 6.25e-05 step-time 0.10s wps 46.13K ppl 41.91 gN 6.58 dev ppl 70.00, dev bleu 3.1, test ppl 82.57, test bleu 2.4, Fri Apr  6 04:59:25 2018\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'dev_ppl': 69.99870507766636,\n",
       "  'dev_scores': {'bleu': 3.0942624039777042},\n",
       "  'test_ppl': 82.56511778406919,\n",
       "  'test_scores': {'bleu': 2.424018787280079}},\n",
       " 4000)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train an LSTM model with dot-product attention\n",
    "hparams = create_standard_hparams(data_path=os.path.join(\"datasets\", \"nmt_data_vi\"), \n",
    "                                  out_dir=\"nmt_model_dotprodatt\")\n",
    "hparams.add_hparam(\"attention_cell_class\", LSTMCellWithDotProductAttention)\n",
    "train(hparams, AttentionalModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Vocab file datasets/nmt_data_vi/vocab.vi exists\n",
      "# Vocab file datasets/nmt_data_vi/vocab.en exists\n",
      "# creating train graph ...\n",
      "  num_layers = 1, num_residual_layers=0\n",
      "  cell 0  LSTM, forget_bias=1  DropoutWrapper, dropout=0.2   DeviceWrapper, device=/gpu:0\n",
      "  cell 0512\n",
      "  DropoutWrapper, dropout=0.2   DropoutWrapper  DeviceWrapper, device=/gpu:0\n",
      "  learning_rate=0.001, warmup_steps=0, warmup_scheme=t2t\n",
      "  decay_scheme=luong234, start_decay_step=2666, decay_steps 333, decay_factor 0.5\n",
      "# Trainable variables\n",
      "  embeddings/encoder/embedding_encoder:0, (7709, 512), /device:GPU:0\n",
      "  embeddings/decoder/embedding_decoder:0, (17191, 512), /device:GPU:0\n",
      "  dynamic_seq2seq/encoder/rnn/basic_lstm_cell/kernel:0, (1024, 2048), /device:GPU:0\n",
      "  dynamic_seq2seq/encoder/rnn/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/lstm_cell_with_bilinear_attention/kernel:0, (1024, 2048), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/lstm_cell_with_bilinear_attention/bias:0, (2048,), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/lstm_cell_with_bilinear_attention/W_att:0, (512, 512), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/lstm_cell_with_bilinear_attention/W_c:0, (1024, 256), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/output_projection/kernel:0, (256, 17191), \n",
      "# creating eval graph ...\n",
      "  num_layers = 1, num_residual_layers=0\n",
      "  cell 0  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\n",
      "  cell 0512\n",
      "  LSTMCellWithBilinearAttention, dropout=0   LSTMCellWithBilinearAttention  DeviceWrapper, device=/gpu:0\n",
      "# Trainable variables\n",
      "  embeddings/encoder/embedding_encoder:0, (7709, 512), /device:GPU:0\n",
      "  embeddings/decoder/embedding_decoder:0, (17191, 512), /device:GPU:0\n",
      "  dynamic_seq2seq/encoder/rnn/basic_lstm_cell/kernel:0, (1024, 2048), /device:GPU:0\n",
      "  dynamic_seq2seq/encoder/rnn/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/lstm_cell_with_bilinear_attention/kernel:0, (1024, 2048), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/lstm_cell_with_bilinear_attention/bias:0, (2048,), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/lstm_cell_with_bilinear_attention/W_att:0, (512, 512), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/lstm_cell_with_bilinear_attention/W_c:0, (1024, 256), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/output_projection/kernel:0, (256, 17191), \n",
      "# creating infer graph ...\n",
      "  num_layers = 1, num_residual_layers=0\n",
      "  cell 0  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\n",
      "  cell 0512\n",
      "  LSTMCellWithBilinearAttention, dropout=0   LSTMCellWithBilinearAttention  DeviceWrapper, device=/gpu:0\n",
      "# Trainable variables\n",
      "  embeddings/encoder/embedding_encoder:0, (7709, 512), /device:GPU:0\n",
      "  embeddings/decoder/embedding_decoder:0, (17191, 512), /device:GPU:0\n",
      "  dynamic_seq2seq/encoder/rnn/basic_lstm_cell/kernel:0, (1024, 2048), /device:GPU:0\n",
      "  dynamic_seq2seq/encoder/rnn/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/lstm_cell_with_bilinear_attention/kernel:0, (1024, 2048), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/lstm_cell_with_bilinear_attention/bias:0, (2048,), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/lstm_cell_with_bilinear_attention/W_att:0, (512, 512), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/lstm_cell_with_bilinear_attention/W_c:0, (1024, 256), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/output_projection/kernel:0, (256, 17191), \n",
      "  created train model with fresh parameters, time 0.33s\n",
      "  created infer model with fresh parameters, time 0.07s\n",
      "  # 776\n",
      "    src: Lúc ấy rất bận rộn , tôi đang hơi vội .\n",
      "    ref: It was busy , I was in a bit of a hurry .\n",
      "    nmt: Koolhaas unlikely suspended Iran past fragment fragment fragment fragment Up Up virtuality virtuality Up rolls yeast constructed clicks religion religion religion Talking\n",
      "  created eval model with fresh parameters, time 0.10s\n",
      "  eval dev: perplexity 17320.00, time 0s, Fri Apr  6 04:59:29 2018.\n",
      "  eval test: perplexity 17342.24, time 0s, Fri Apr  6 04:59:30 2018.\n",
      "  created infer model with fresh parameters, time 0.05s\n",
      "# Start step 0, lr 0.001, Fri Apr  6 04:59:30 2018\n",
      "# Init train iterator, skipping 0 elements\n",
      "  step 100 lr 0.001 step-time 0.25s wps 18.96K ppl 615.62 gN 14.44 bleu 0.00, Fri Apr  6 04:59:54 2018\n",
      "  step 200 lr 0.001 step-time 0.11s wps 43.82K ppl 363.38 gN 10.98 bleu 0.00, Fri Apr  6 05:00:05 2018\n",
      "  step 300 lr 0.001 step-time 0.10s wps 45.18K ppl 316.73 gN 9.15 bleu 0.00, Fri Apr  6 05:00:15 2018\n",
      "  step 400 lr 0.001 step-time 0.10s wps 45.45K ppl 276.90 gN 9.30 bleu 0.00, Fri Apr  6 05:00:25 2018\n",
      "  step 500 lr 0.001 step-time 0.10s wps 45.40K ppl 241.34 gN 8.86 bleu 0.00, Fri Apr  6 05:00:35 2018\n",
      "  step 600 lr 0.001 step-time 0.10s wps 45.18K ppl 209.24 gN 8.48 bleu 0.00, Fri Apr  6 05:00:45 2018\n",
      "  step 700 lr 0.001 step-time 0.10s wps 45.35K ppl 189.11 gN 8.04 bleu 0.00, Fri Apr  6 05:00:56 2018\n",
      "  step 800 lr 0.001 step-time 0.10s wps 45.33K ppl 171.78 gN 7.93 bleu 0.00, Fri Apr  6 05:01:06 2018\n",
      "  step 900 lr 0.001 step-time 0.10s wps 44.94K ppl 157.53 gN 7.35 bleu 0.00, Fri Apr  6 05:01:16 2018\n",
      "  step 1000 lr 0.001 step-time 0.10s wps 45.34K ppl 149.13 gN 7.23 bleu 0.00, Fri Apr  6 05:01:26 2018\n",
      "# Save eval, global step 1000\n",
      "INFO:tensorflow:Restoring parameters from nmt_model_bilinearatt/translate.ckpt-1000\n",
      "  loaded infer model parameters from nmt_model_bilinearatt/translate.ckpt-1000, time 0.07s\n",
      "  # 611\n",
      "    src: bây giờ là 2 loại nữ trang khác nhau\n",
      "    ref: Here are two different jewelry displays .\n",
      "    nmt: Now is is a of of of . . .\n",
      "INFO:tensorflow:Restoring parameters from nmt_model_bilinearatt/translate.ckpt-1000\n",
      "  loaded eval model parameters from nmt_model_bilinearatt/translate.ckpt-1000, time 0.08s\n",
      "  eval dev: perplexity 147.12, time 0s, Fri Apr  6 05:01:28 2018.\n",
      "  eval test: perplexity 171.19, time 0s, Fri Apr  6 05:01:29 2018.\n",
      "# Finished an epoch, step 1043. Perform external evaluation\n",
      "INFO:tensorflow:Restoring parameters from nmt_model_bilinearatt/translate.ckpt-1000\n",
      "  loaded infer model parameters from nmt_model_bilinearatt/translate.ckpt-1000, time 0.07s\n",
      "  # 709\n",
      "    src: Tôi chẩn bệnh và bắt đầu điều trị cho bà .\n",
      "    ref: I made it and I set to work treating her .\n",
      "    nmt: I was my to and and and . .\n",
      "INFO:tensorflow:Restoring parameters from nmt_model_bilinearatt/translate.ckpt-1000\n",
      "  loaded infer model parameters from nmt_model_bilinearatt/translate.ckpt-1000, time 0.07s\n",
      "# External evaluation, global step 1000\n",
      "  decoding to output nmt_model_bilinearatt/output_dev.\n",
      "  done, num sentences 1553, num translations per input 1, time 7s, Fri Apr  6 05:01:40 2018.\n",
      "  bleu dev: 1.2\n",
      "  saving hparams to nmt_model_bilinearatt/hparams\n",
      "# External evaluation, global step 1000\n",
      "  decoding to output nmt_model_bilinearatt/output_test.\n",
      "  done, num sentences 1268, num translations per input 1, time 6s, Fri Apr  6 05:01:47 2018.\n",
      "  bleu test: 0.9\n",
      "  saving hparams to nmt_model_bilinearatt/hparams\n",
      "  step 1100 lr 0.001 step-time 0.23s wps 19.37K ppl 137.60 gN 9.01 bleu 1.23, Fri Apr  6 05:02:06 2018\n",
      "  step 1200 lr 0.001 step-time 0.12s wps 39.51K ppl 125.14 gN 7.00 bleu 1.23, Fri Apr  6 05:02:18 2018\n",
      "  step 1300 lr 0.001 step-time 0.10s wps 45.13K ppl 114.06 gN 6.71 bleu 1.23, Fri Apr  6 05:02:28 2018\n",
      "  step 1400 lr 0.001 step-time 0.10s wps 45.39K ppl 111.27 gN 6.62 bleu 1.23, Fri Apr  6 05:02:38 2018\n",
      "  step 1500 lr 0.001 step-time 0.10s wps 45.32K ppl 105.14 gN 6.87 bleu 1.23, Fri Apr  6 05:02:49 2018\n",
      "  step 1600 lr 0.001 step-time 0.10s wps 45.17K ppl 101.00 gN 6.71 bleu 1.23, Fri Apr  6 05:02:59 2018\n",
      "  step 1700 lr 0.001 step-time 0.10s wps 45.41K ppl 98.54 gN 6.77 bleu 1.23, Fri Apr  6 05:03:09 2018\n",
      "  step 1800 lr 0.001 step-time 0.10s wps 45.18K ppl 95.32 gN 6.79 bleu 1.23, Fri Apr  6 05:03:19 2018\n",
      "  step 1900 lr 0.001 step-time 0.10s wps 45.11K ppl 88.55 gN 6.89 bleu 1.23, Fri Apr  6 05:03:29 2018\n",
      "  step 2000 lr 0.001 step-time 0.10s wps 45.59K ppl 89.84 gN 7.42 bleu 1.23, Fri Apr  6 05:03:40 2018\n",
      "# Save eval, global step 2000\n",
      "INFO:tensorflow:Restoring parameters from nmt_model_bilinearatt/translate.ckpt-2000\n",
      "  loaded infer model parameters from nmt_model_bilinearatt/translate.ckpt-2000, time 0.07s\n",
      "  # 1044\n",
      "    src: Vì vậy , nói cách khác , tương lai dường như chùn lại một năm mỗi năm cho cả đời người .\n",
      "    ref: So in other words , the future has kind of been shrinking one year per year for my whole lifetime .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    nmt: So , , the is is to to the the of of , , the the of of years , the a of of years .\n",
      "INFO:tensorflow:Restoring parameters from nmt_model_bilinearatt/translate.ckpt-2000\n",
      "  loaded eval model parameters from nmt_model_bilinearatt/translate.ckpt-2000, time 0.07s\n",
      "  eval dev: perplexity 93.37, time 0s, Fri Apr  6 05:03:41 2018.\n",
      "  eval test: perplexity 111.08, time 0s, Fri Apr  6 05:03:42 2018.\n",
      "# Finished an epoch, step 2086. Perform external evaluation\n",
      "INFO:tensorflow:Restoring parameters from nmt_model_bilinearatt/translate.ckpt-2000\n",
      "  loaded infer model parameters from nmt_model_bilinearatt/translate.ckpt-2000, time 0.07s\n",
      "  # 1040\n",
      "    src: Bởi vì quá trình chuyển giao này có vẻ rất khó đoán biết khi chúng ta đang ở ngay giữa của quá trình ấy .\n",
      "    ref: Because the transition seems very , very confusing when we &apos;re right in the middle of it .\n",
      "    nmt: Because this &apos;s is important important because because &apos;re we to to the the of of in in . . &apos;s &apos;s . .\n",
      "INFO:tensorflow:Restoring parameters from nmt_model_bilinearatt/translate.ckpt-2000\n",
      "  loaded infer model parameters from nmt_model_bilinearatt/translate.ckpt-2000, time 0.07s\n",
      "# External evaluation, global step 2000\n",
      "  decoding to output nmt_model_bilinearatt/output_dev.\n",
      "  done, num sentences 1553, num translations per input 1, time 12s, Fri Apr  6 05:04:03 2018.\n",
      "  bleu dev: 1.6\n",
      "  saving hparams to nmt_model_bilinearatt/hparams\n",
      "# External evaluation, global step 2000\n",
      "  decoding to output nmt_model_bilinearatt/output_test.\n",
      "  done, num sentences 1268, num translations per input 1, time 12s, Fri Apr  6 05:04:17 2018.\n",
      "  bleu test: 1.2\n",
      "  saving hparams to nmt_model_bilinearatt/hparams\n",
      "  step 2100 lr 0.001 step-time 0.22s wps 20.52K ppl 81.66 gN 6.77 bleu 1.58, Fri Apr  6 05:04:31 2018\n",
      "  step 2200 lr 0.001 step-time 0.13s wps 35.49K ppl 68.80 gN 6.74 bleu 1.58, Fri Apr  6 05:04:44 2018\n",
      "  step 2300 lr 0.001 step-time 0.10s wps 45.58K ppl 68.76 gN 6.72 bleu 1.58, Fri Apr  6 05:04:54 2018\n",
      "  step 2400 lr 0.001 step-time 0.10s wps 45.34K ppl 67.18 gN 6.62 bleu 1.58, Fri Apr  6 05:05:04 2018\n",
      "  step 2500 lr 0.001 step-time 0.10s wps 45.42K ppl 65.83 gN 6.83 bleu 1.58, Fri Apr  6 05:05:14 2018\n",
      "  step 2600 lr 0.001 step-time 0.10s wps 45.42K ppl 65.50 gN 6.71 bleu 1.58, Fri Apr  6 05:05:24 2018\n",
      "  step 2700 lr 0.001 step-time 0.10s wps 45.19K ppl 63.39 gN 6.57 bleu 1.58, Fri Apr  6 05:05:35 2018\n",
      "  step 2800 lr 0.001 step-time 0.10s wps 45.45K ppl 62.40 gN 6.64 bleu 1.58, Fri Apr  6 05:05:45 2018\n",
      "  step 2900 lr 0.001 step-time 0.10s wps 45.62K ppl 62.30 gN 6.71 bleu 1.58, Fri Apr  6 05:05:55 2018\n",
      "  step 3000 lr 0.0005 step-time 0.10s wps 45.47K ppl 60.25 gN 6.73 bleu 1.58, Fri Apr  6 05:06:05 2018\n",
      "# Save eval, global step 3000\n",
      "INFO:tensorflow:Restoring parameters from nmt_model_bilinearatt/translate.ckpt-3000\n",
      "  loaded infer model parameters from nmt_model_bilinearatt/translate.ckpt-3000, time 0.07s\n",
      "  # 414\n",
      "    src: Tôi sẽ nói về một ý tưởng nho nhỏ\n",
      "    ref: I &apos;m going to speak about a tiny , little idea .\n",
      "    nmt: I I just to about about little little . .\n",
      "INFO:tensorflow:Restoring parameters from nmt_model_bilinearatt/translate.ckpt-3000\n",
      "  loaded eval model parameters from nmt_model_bilinearatt/translate.ckpt-3000, time 0.07s\n",
      "  eval dev: perplexity 74.82, time 0s, Fri Apr  6 05:06:06 2018.\n",
      "  eval test: perplexity 88.52, time 0s, Fri Apr  6 05:06:07 2018.\n",
      "  step 3100 lr 0.0005 step-time 0.10s wps 45.57K ppl 57.63 gN 6.21 bleu 1.58, Fri Apr  6 05:06:17 2018\n",
      "# Finished an epoch, step 3129. Perform external evaluation\n",
      "INFO:tensorflow:Restoring parameters from nmt_model_bilinearatt/translate.ckpt-3000\n",
      "  loaded infer model parameters from nmt_model_bilinearatt/translate.ckpt-3000, time 0.07s\n",
      "  # 303\n",
      "    src: có một lần tôi đến và nghe họ nói sau vài tiếng , bà Park quay sang và nói : &quot; Nào , Bryan , hãy nói cho tôi nghe về đơn kiến nghị tính công bằng của tư pháp\n",
      "    ref: And one time I was over there listening to these women talk , and after a couple of hours Ms. Parks turned to me and she said , &quot; Now Bryan , tell me what the Equal Justice Initiative is .\n",
      "    nmt: I was a to , , I I to to about about and and , , , , , , , , , , , , , , , , , , , , , , , , , ,\n",
      "INFO:tensorflow:Restoring parameters from nmt_model_bilinearatt/translate.ckpt-3000\n",
      "  loaded infer model parameters from nmt_model_bilinearatt/translate.ckpt-3000, time 0.07s\n",
      "# External evaluation, global step 3000\n",
      "  decoding to output nmt_model_bilinearatt/output_dev.\n",
      "  done, num sentences 1553, num translations per input 1, time 14s, Fri Apr  6 05:06:34 2018.\n",
      "  bleu dev: 1.8\n",
      "  saving hparams to nmt_model_bilinearatt/hparams\n",
      "# External evaluation, global step 3000\n",
      "  decoding to output nmt_model_bilinearatt/output_test.\n",
      "  done, num sentences 1268, num translations per input 1, time 13s, Fri Apr  6 05:06:49 2018.\n",
      "  bleu test: 1.3\n",
      "  saving hparams to nmt_model_bilinearatt/hparams\n",
      "  step 3200 lr 0.0005 step-time 0.23s wps 19.40K ppl 47.43 gN 6.35 bleu 1.84, Fri Apr  6 05:07:09 2018\n",
      "  step 3300 lr 0.0005 step-time 0.11s wps 40.80K ppl 44.29 gN 6.60 bleu 1.84, Fri Apr  6 05:07:21 2018\n",
      "  step 3400 lr 0.00025 step-time 0.10s wps 45.26K ppl 44.21 gN 6.56 bleu 1.84, Fri Apr  6 05:07:31 2018\n",
      "  step 3500 lr 0.00025 step-time 0.10s wps 45.31K ppl 43.64 gN 6.45 bleu 1.84, Fri Apr  6 05:07:41 2018\n",
      "  step 3600 lr 0.00025 step-time 0.10s wps 45.57K ppl 44.49 gN 6.54 bleu 1.84, Fri Apr  6 05:07:51 2018\n",
      "  step 3700 lr 0.000125 step-time 0.10s wps 45.65K ppl 43.56 gN 6.62 bleu 1.84, Fri Apr  6 05:08:01 2018\n",
      "  step 3800 lr 0.000125 step-time 0.10s wps 45.03K ppl 43.41 gN 6.52 bleu 1.84, Fri Apr  6 05:08:12 2018\n",
      "  step 3900 lr 0.000125 step-time 0.10s wps 45.19K ppl 43.44 gN 6.55 bleu 1.84, Fri Apr  6 05:08:22 2018\n",
      "  step 4000 lr 6.25e-05 step-time 0.10s wps 45.36K ppl 43.11 gN 6.54 bleu 1.84, Fri Apr  6 05:08:32 2018\n",
      "# Save eval, global step 4000\n",
      "INFO:tensorflow:Restoring parameters from nmt_model_bilinearatt/translate.ckpt-4000\n",
      "  loaded infer model parameters from nmt_model_bilinearatt/translate.ckpt-4000, time 0.07s\n",
      "  # 105\n",
      "    src: &quot; Bởi vì từ sàng các chị đã cầm tay bà , &quot; ông nói .\n",
      "    ref: &quot; Because you have been holding it since this morning , &quot; he said .\n",
      "    nmt: &quot; Because you your your , , , , , , know know\n",
      "INFO:tensorflow:Restoring parameters from nmt_model_bilinearatt/translate.ckpt-4000\n",
      "  loaded eval model parameters from nmt_model_bilinearatt/translate.ckpt-4000, time 0.07s\n",
      "  eval dev: perplexity 70.76, time 0s, Fri Apr  6 05:08:33 2018.\n",
      "  eval test: perplexity 83.82, time 0s, Fri Apr  6 05:08:34 2018.\n",
      "INFO:tensorflow:Restoring parameters from nmt_model_bilinearatt/translate.ckpt-4000\n",
      "  loaded infer model parameters from nmt_model_bilinearatt/translate.ckpt-4000, time 0.07s\n",
      "  # 68\n",
      "    src: Thế là tôi nói về nạn thanh niên thất nghiệp và giáo dục , và về những người bị xã hội cách li , bị mất quyền lợi và bỏ rơi .\n",
      "    ref: So I spoke out on youth unemployment and education and the neglect of the marginalized and the disenfranchised .\n",
      "    nmt: So I I about about and and about and , , , , , , , , , , , , , , , , , , , , , , ,\n",
      "INFO:tensorflow:Restoring parameters from nmt_model_bilinearatt/translate.ckpt-4000\n",
      "  loaded eval model parameters from nmt_model_bilinearatt/translate.ckpt-4000, time 0.07s\n",
      "  eval dev: perplexity 70.76, time 0s, Fri Apr  6 05:08:43 2018.\n",
      "  eval test: perplexity 83.82, time 0s, Fri Apr  6 05:08:44 2018.\n",
      "INFO:tensorflow:Restoring parameters from nmt_model_bilinearatt/translate.ckpt-4000\n",
      "  loaded infer model parameters from nmt_model_bilinearatt/translate.ckpt-4000, time 0.07s\n",
      "# External evaluation, global step 4000\n",
      "  decoding to output nmt_model_bilinearatt/output_dev.\n",
      "  done, num sentences 1553, num translations per input 1, time 11s, Fri Apr  6 05:08:56 2018.\n",
      "  bleu dev: 2.5\n",
      "  saving hparams to nmt_model_bilinearatt/hparams\n",
      "# External evaluation, global step 4000\n",
      "  decoding to output nmt_model_bilinearatt/output_test.\n",
      "  done, num sentences 1268, num translations per input 1, time 11s, Fri Apr  6 05:09:08 2018.\n",
      "  bleu test: 1.9\n",
      "  saving hparams to nmt_model_bilinearatt/hparams\n",
      "# Final, step 4000 lr 6.25e-05 step-time 0.10s wps 45.36K ppl 43.11 gN 6.54 dev ppl 70.76, dev bleu 2.5, test ppl 83.82, test bleu 1.9, Fri Apr  6 05:09:08 2018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Done training!, time 578s, Fri Apr  6 05:09:08 2018.\n",
      "# Start evaluating saved best models.\n",
      "INFO:tensorflow:Restoring parameters from nmt_model_bilinearatt/best_bleu/translate.ckpt-4000\n",
      "  loaded infer model parameters from nmt_model_bilinearatt/best_bleu/translate.ckpt-4000, time 0.07s\n",
      "  # 999\n",
      "    src: Và điều đó tạo nên một loại mạng xã hội quanh bộ sưu tập ảnh kĩ thuật số mà bạn chụp được .\n",
      "    ref: And it creates this kind of social network around a collection of digital photographs that you &apos;ve actually taken .\n",
      "    nmt: And it &apos;s a a of of social social that that research the that that &apos;ve &apos;ve shown in you . . .\n",
      "INFO:tensorflow:Restoring parameters from nmt_model_bilinearatt/best_bleu/translate.ckpt-4000\n",
      "  loaded eval model parameters from nmt_model_bilinearatt/best_bleu/translate.ckpt-4000, time 0.07s\n",
      "  eval dev: perplexity 70.76, time 0s, Fri Apr  6 05:09:09 2018.\n",
      "  eval test: perplexity 83.82, time 0s, Fri Apr  6 05:09:10 2018.\n",
      "INFO:tensorflow:Restoring parameters from nmt_model_bilinearatt/best_bleu/translate.ckpt-4000\n",
      "  loaded infer model parameters from nmt_model_bilinearatt/best_bleu/translate.ckpt-4000, time 0.07s\n",
      "# External evaluation, global step 4000\n",
      "  decoding to output nmt_model_bilinearatt/output_dev.\n",
      "  done, num sentences 1553, num translations per input 1, time 11s, Fri Apr  6 05:09:22 2018.\n",
      "  bleu dev: 2.5\n",
      "  saving hparams to nmt_model_bilinearatt/hparams\n",
      "# External evaluation, global step 4000\n",
      "  decoding to output nmt_model_bilinearatt/output_test.\n",
      "  done, num sentences 1268, num translations per input 1, time 11s, Fri Apr  6 05:09:34 2018.\n",
      "  bleu test: 1.9\n",
      "  saving hparams to nmt_model_bilinearatt/hparams\n",
      "# Best bleu, step 4000 lr 6.25e-05 step-time 0.10s wps 45.36K ppl 43.11 gN 6.54 dev ppl 70.76, dev bleu 2.5, test ppl 83.82, test bleu 1.9, Fri Apr  6 05:09:34 2018\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'dev_ppl': 70.7569787824054,\n",
       "  'dev_scores': {'bleu': 2.480345357372072},\n",
       "  'test_ppl': 83.8243771651258,\n",
       "  'test_scores': {'bleu': 1.8926691236709252}},\n",
       " 4000)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train an LSTM model with bilinear attention\n",
    "hparams = create_standard_hparams(data_path=os.path.join(\"datasets\", \"nmt_data_vi\"),\n",
    "                                  out_dir=\"nmt_model_bilinearatt\")\n",
    "hparams.add_hparam(\"attention_cell_class\", LSTMCellWithBilinearAttention)\n",
    "train(hparams, AttentionalModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Vocab file datasets/nmt_data_vi/vocab.vi exists\n",
      "# Vocab file datasets/nmt_data_vi/vocab.en exists\n",
      "# creating train graph ...\n",
      "  num_layers = 1, num_residual_layers=0\n",
      "  cell 0  LSTM, forget_bias=1  DropoutWrapper, dropout=0.2   DeviceWrapper, device=/gpu:0\n",
      "  cell 0512\n",
      "  DropoutWrapper, dropout=0.2   DropoutWrapper  DeviceWrapper, device=/gpu:0\n",
      "  learning_rate=0.001, warmup_steps=0, warmup_scheme=t2t\n",
      "  decay_scheme=luong234, start_decay_step=2666, decay_steps 333, decay_factor 0.5\n",
      "# Trainable variables\n",
      "  embeddings/encoder/embedding_encoder:0, (7709, 512), /device:GPU:0\n",
      "  embeddings/decoder/embedding_decoder:0, (17191, 512), /device:GPU:0\n",
      "  dynamic_seq2seq/encoder/rnn/basic_lstm_cell/kernel:0, (1024, 2048), /device:GPU:0\n",
      "  dynamic_seq2seq/encoder/rnn/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/lstm_cell_with_feed_forward_attention/kernel:0, (1024, 2048), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/lstm_cell_with_feed_forward_attention/bias:0, (2048,), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/lstm_cell_with_feed_forward_attention/W_att_1:0, (1024, 512), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/lstm_cell_with_feed_forward_attention/W_att_2:0, (512, 1), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/lstm_cell_with_feed_forward_attention/W_c:0, (1024, 256), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/output_projection/kernel:0, (256, 17191), \n",
      "# creating eval graph ...\n",
      "  num_layers = 1, num_residual_layers=0\n",
      "  cell 0  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\n",
      "  cell 0512\n",
      "  LSTMCellWithFeedForwardAttention, dropout=0   LSTMCellWithFeedForwardAttention  DeviceWrapper, device=/gpu:0\n",
      "# Trainable variables\n",
      "  embeddings/encoder/embedding_encoder:0, (7709, 512), /device:GPU:0\n",
      "  embeddings/decoder/embedding_decoder:0, (17191, 512), /device:GPU:0\n",
      "  dynamic_seq2seq/encoder/rnn/basic_lstm_cell/kernel:0, (1024, 2048), /device:GPU:0\n",
      "  dynamic_seq2seq/encoder/rnn/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/lstm_cell_with_feed_forward_attention/kernel:0, (1024, 2048), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/lstm_cell_with_feed_forward_attention/bias:0, (2048,), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/lstm_cell_with_feed_forward_attention/W_att_1:0, (1024, 512), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/lstm_cell_with_feed_forward_attention/W_att_2:0, (512, 1), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/lstm_cell_with_feed_forward_attention/W_c:0, (1024, 256), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/output_projection/kernel:0, (256, 17191), \n",
      "# creating infer graph ...\n",
      "  num_layers = 1, num_residual_layers=0\n",
      "  cell 0  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\n",
      "  cell 0512\n",
      "  LSTMCellWithFeedForwardAttention, dropout=0   LSTMCellWithFeedForwardAttention  DeviceWrapper, device=/gpu:0\n",
      "# Trainable variables\n",
      "  embeddings/encoder/embedding_encoder:0, (7709, 512), /device:GPU:0\n",
      "  embeddings/decoder/embedding_decoder:0, (17191, 512), /device:GPU:0\n",
      "  dynamic_seq2seq/encoder/rnn/basic_lstm_cell/kernel:0, (1024, 2048), /device:GPU:0\n",
      "  dynamic_seq2seq/encoder/rnn/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/lstm_cell_with_feed_forward_attention/kernel:0, (1024, 2048), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/lstm_cell_with_feed_forward_attention/bias:0, (2048,), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/lstm_cell_with_feed_forward_attention/W_att_1:0, (1024, 512), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/lstm_cell_with_feed_forward_attention/W_att_2:0, (512, 1), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/lstm_cell_with_feed_forward_attention/W_c:0, (1024, 256), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/output_projection/kernel:0, (256, 17191), \n",
      "  created train model with fresh parameters, time 0.35s\n",
      "  created infer model with fresh parameters, time 0.08s\n",
      "  # 1038\n",
      "    src: Và vì vậy , điều mà tôi đang muốn hỏi , điều mà tôi vẫn đang tự hỏi mình , là trạng thái mới mà thế giới đang tồn tại là gì ?\n",
      "    ref: And so what I &apos;m trying to ask , what I &apos;ve been asking myself , is what &apos;s this new way that the world is ?\n",
      "    nmt: invested heading heading heading heading inbox inbox inbox wearing wearing wearing abalone abalone abalone abalone USB USB airplane emailed airplane pure pure pure pure pure pure weightlessness weightlessness weightlessness weightlessness weightlessness weightlessness weightlessness weightlessness weightlessness shifts shifts shifts shifts shifts shifts shifts pregnancy pregnancy closely closely closely closely layered layered layered layered layered confines confines confines ambiguous ambiguous ambiguous ambiguous Bronx Bronx Bronx Bronx Bronx Bronx\n",
      "  created eval model with fresh parameters, time 0.10s\n",
      "  eval dev: perplexity 17311.03, time 1s, Fri Apr  6 05:09:39 2018.\n",
      "  eval test: perplexity 17346.23, time 1s, Fri Apr  6 05:09:40 2018.\n",
      "  created infer model with fresh parameters, time 0.06s\n",
      "# Start step 0, lr 0.001, Fri Apr  6 05:09:40 2018\n",
      "# Init train iterator, skipping 0 elements\n",
      "  step 100 lr 0.001 step-time 0.25s wps 18.35K ppl 614.16 gN 15.21 bleu 0.00, Fri Apr  6 05:10:05 2018\n",
      "  step 200 lr 0.001 step-time 0.11s wps 40.66K ppl 374.32 gN 10.74 bleu 0.00, Fri Apr  6 05:10:16 2018\n",
      "  step 300 lr 0.001 step-time 0.11s wps 41.60K ppl 314.21 gN 8.83 bleu 0.00, Fri Apr  6 05:10:27 2018\n",
      "  step 400 lr 0.001 step-time 0.11s wps 41.69K ppl 263.61 gN 8.82 bleu 0.00, Fri Apr  6 05:10:38 2018\n",
      "  step 500 lr 0.001 step-time 0.11s wps 41.63K ppl 218.25 gN 8.62 bleu 0.00, Fri Apr  6 05:10:49 2018\n",
      "  step 600 lr 0.001 step-time 0.11s wps 41.71K ppl 181.13 gN 9.31 bleu 0.00, Fri Apr  6 05:11:00 2018\n",
      "  step 700 lr 0.001 step-time 0.11s wps 41.69K ppl 155.25 gN 9.26 bleu 0.00, Fri Apr  6 05:11:12 2018\n",
      "  step 800 lr 0.001 step-time 0.11s wps 41.32K ppl 126.37 gN 7.48 bleu 0.00, Fri Apr  6 05:11:23 2018\n",
      "  step 900 lr 0.001 step-time 0.11s wps 41.33K ppl 113.05 gN 7.85 bleu 0.00, Fri Apr  6 05:11:34 2018\n",
      "  step 1000 lr 0.001 step-time 0.11s wps 41.90K ppl 100.62 gN 7.85 bleu 0.00, Fri Apr  6 05:11:45 2018\n",
      "# Save eval, global step 1000\n",
      "INFO:tensorflow:Restoring parameters from nmt_model_ffatt/translate.ckpt-1000\n",
      "  loaded infer model parameters from nmt_model_ffatt/translate.ckpt-1000, time 0.08s\n",
      "  # 114\n",
      "    src: Tôi không biết .\n",
      "    ref: I don &apos;t know .\n",
      "    nmt: I don &apos;t know .\n",
      "INFO:tensorflow:Restoring parameters from nmt_model_ffatt/translate.ckpt-1000\n",
      "  loaded eval model parameters from nmt_model_ffatt/translate.ckpt-1000, time 0.08s\n",
      "  eval dev: perplexity 97.17, time 1s, Fri Apr  6 05:11:47 2018.\n",
      "  eval test: perplexity 108.32, time 0s, Fri Apr  6 05:11:48 2018.\n",
      "# Finished an epoch, step 1043. Perform external evaluation\n",
      "INFO:tensorflow:Restoring parameters from nmt_model_ffatt/translate.ckpt-1000\n",
      "  loaded infer model parameters from nmt_model_ffatt/translate.ckpt-1000, time 0.07s\n",
      "  # 93\n",
      "    src: Năm 17 tuổi , bà trở thành vợ hai của một ông quan , mẫu thân ông quan này đánh đập bà .\n",
      "    ref: At 17 she became the second wife of a Mandarin whose mother beat her .\n",
      "    nmt: In the , , was was <unk> <unk> a a of of , , he he this this . .\n",
      "INFO:tensorflow:Restoring parameters from nmt_model_ffatt/translate.ckpt-1000\n",
      "  loaded infer model parameters from nmt_model_ffatt/translate.ckpt-1000, time 0.07s\n",
      "# External evaluation, global step 1000\n",
      "  decoding to output nmt_model_ffatt/output_dev.\n",
      "  done, num sentences 1553, num translations per input 1, time 8s, Fri Apr  6 05:12:01 2018.\n",
      "  bleu dev: 3.1\n",
      "  saving hparams to nmt_model_ffatt/hparams\n",
      "# External evaluation, global step 1000\n",
      "  decoding to output nmt_model_ffatt/output_test.\n",
      "  done, num sentences 1268, num translations per input 1, time 8s, Fri Apr  6 05:12:10 2018.\n",
      "  bleu test: 2.7\n",
      "  saving hparams to nmt_model_ffatt/hparams\n",
      "  step 1100 lr 0.001 step-time 0.23s wps 19.43K ppl 87.36 gN 7.68 bleu 3.13, Fri Apr  6 05:12:29 2018\n",
      "  step 1200 lr 0.001 step-time 0.13s wps 35.55K ppl 76.42 gN 7.28 bleu 3.13, Fri Apr  6 05:12:42 2018\n",
      "  step 1300 lr 0.001 step-time 0.14s wps 32.77K ppl 71.06 gN 7.25 bleu 3.13, Fri Apr  6 05:12:56 2018\n",
      "  step 1400 lr 0.001 step-time 0.14s wps 32.76K ppl 68.47 gN 7.87 bleu 3.13, Fri Apr  6 05:13:10 2018\n",
      "  step 1500 lr 0.001 step-time 0.14s wps 32.66K ppl 64.01 gN 7.44 bleu 3.13, Fri Apr  6 05:13:24 2018\n",
      "  step 1600 lr 0.001 step-time 0.14s wps 32.75K ppl 59.66 gN 7.06 bleu 3.13, Fri Apr  6 05:13:38 2018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  step 1700 lr 0.001 step-time 0.14s wps 32.86K ppl 58.02 gN 7.42 bleu 3.13, Fri Apr  6 05:13:53 2018\n",
      "  step 1800 lr 0.001 step-time 0.14s wps 32.77K ppl 55.42 gN 7.52 bleu 3.13, Fri Apr  6 05:14:07 2018\n",
      "  step 1900 lr 0.001 step-time 0.14s wps 32.82K ppl 51.93 gN 7.08 bleu 3.13, Fri Apr  6 05:14:21 2018\n",
      "  step 2000 lr 0.001 step-time 0.14s wps 32.83K ppl 49.65 gN 7.16 bleu 3.13, Fri Apr  6 05:14:35 2018\n",
      "# Save eval, global step 2000\n",
      "INFO:tensorflow:Restoring parameters from nmt_model_ffatt/translate.ckpt-2000\n",
      "  loaded infer model parameters from nmt_model_ffatt/translate.ckpt-2000, time 0.07s\n",
      "  # 281\n",
      "    src: Tuy nhiên , hãy suy nghĩ về họ theo cách hoà nhập với cả cuộc sống của chính chúng ta .\n",
      "    ref: But thinking about them in a way that is integrated in our own lives .\n",
      "    nmt: However , let think think them them the our of in life lives\n",
      "INFO:tensorflow:Restoring parameters from nmt_model_ffatt/translate.ckpt-2000\n",
      "  loaded eval model parameters from nmt_model_ffatt/translate.ckpt-2000, time 0.08s\n",
      "  eval dev: perplexity 55.95, time 1s, Fri Apr  6 05:14:37 2018.\n",
      "  eval test: perplexity 60.59, time 1s, Fri Apr  6 05:14:38 2018.\n",
      "# Finished an epoch, step 2086. Perform external evaluation\n",
      "INFO:tensorflow:Restoring parameters from nmt_model_ffatt/translate.ckpt-2000\n",
      "  loaded infer model parameters from nmt_model_ffatt/translate.ckpt-2000, time 0.07s\n",
      "  # 343\n",
      "    src: Vâng , Bryan , quan toà có quyền lực như thế ,\n",
      "    ref: Yeah , Bryan , the judge has some magic power .\n",
      "    nmt: Well , <unk> , is is to to . .\n",
      "INFO:tensorflow:Restoring parameters from nmt_model_ffatt/translate.ckpt-2000\n",
      "  loaded infer model parameters from nmt_model_ffatt/translate.ckpt-2000, time 0.07s\n",
      "# External evaluation, global step 2000\n",
      "  decoding to output nmt_model_ffatt/output_dev.\n",
      "  done, num sentences 1553, num translations per input 1, time 14s, Fri Apr  6 05:15:05 2018.\n",
      "  bleu dev: 5.3\n",
      "  saving hparams to nmt_model_ffatt/hparams\n",
      "# External evaluation, global step 2000\n",
      "  decoding to output nmt_model_ffatt/output_test.\n",
      "  done, num sentences 1268, num translations per input 1, time 13s, Fri Apr  6 05:15:19 2018.\n",
      "  bleu test: 4.9\n",
      "  saving hparams to nmt_model_ffatt/hparams\n",
      "  step 2100 lr 0.001 step-time 0.27s wps 16.64K ppl 46.01 gN 7.16 bleu 5.33, Fri Apr  6 05:15:34 2018\n",
      "  step 2200 lr 0.001 step-time 0.15s wps 30.62K ppl 38.94 gN 7.20 bleu 5.33, Fri Apr  6 05:15:49 2018\n",
      "  step 2300 lr 0.001 step-time 0.14s wps 32.90K ppl 38.59 gN 7.30 bleu 5.33, Fri Apr  6 05:16:03 2018\n",
      "  step 2400 lr 0.001 step-time 0.14s wps 32.78K ppl 37.00 gN 7.07 bleu 5.33, Fri Apr  6 05:16:17 2018\n",
      "  step 2500 lr 0.001 step-time 0.14s wps 32.97K ppl 37.48 gN 8.00 bleu 5.33, Fri Apr  6 05:16:31 2018\n",
      "  step 2600 lr 0.001 step-time 0.14s wps 32.90K ppl 36.26 gN 7.26 bleu 5.33, Fri Apr  6 05:16:45 2018\n",
      "  step 2700 lr 0.001 step-time 0.14s wps 32.89K ppl 35.37 gN 6.98 bleu 5.33, Fri Apr  6 05:16:59 2018\n",
      "  step 2800 lr 0.001 step-time 0.14s wps 32.69K ppl 34.30 gN 7.19 bleu 5.33, Fri Apr  6 05:17:13 2018\n",
      "  step 2900 lr 0.001 step-time 0.14s wps 32.80K ppl 33.82 gN 7.01 bleu 5.33, Fri Apr  6 05:17:27 2018\n",
      "  step 3000 lr 0.0005 step-time 0.14s wps 32.94K ppl 33.29 gN 7.04 bleu 5.33, Fri Apr  6 05:17:41 2018\n",
      "# Save eval, global step 3000\n",
      "INFO:tensorflow:Restoring parameters from nmt_model_ffatt/translate.ckpt-3000\n",
      "  loaded infer model parameters from nmt_model_ffatt/translate.ckpt-3000, time 0.07s\n",
      "  # 375\n",
      "    src: Ông luôn nhìn vào qua cánh cửa sổ , và ông có thể nghe hết tất cả những tiếng la hét .\n",
      "    ref: And he kept looking through the window , and he could hear all of this holler .\n",
      "    nmt: He &apos;s looking at the window , , he he hear all all the the . .\n",
      "INFO:tensorflow:Restoring parameters from nmt_model_ffatt/translate.ckpt-3000\n",
      "  loaded eval model parameters from nmt_model_ffatt/translate.ckpt-3000, time 0.08s\n",
      "  eval dev: perplexity 43.07, time 1s, Fri Apr  6 05:17:44 2018.\n",
      "  eval test: perplexity 43.68, time 1s, Fri Apr  6 05:17:45 2018.\n",
      "  step 3100 lr 0.0005 step-time 0.14s wps 32.85K ppl 32.69 gN 6.73 bleu 5.33, Fri Apr  6 05:17:59 2018\n",
      "# Finished an epoch, step 3129. Perform external evaluation\n",
      "INFO:tensorflow:Restoring parameters from nmt_model_ffatt/translate.ckpt-3000\n",
      "  loaded infer model parameters from nmt_model_ffatt/translate.ckpt-3000, time 0.07s\n",
      "  # 802\n",
      "    src: Cô độc , tủi hổ , không được trợ giúp .\n",
      "    ref: Alone , ashamed and unsupported .\n",
      "    nmt: She , , , , , , , , , , , , , , , , , , , , ,\n",
      "INFO:tensorflow:Restoring parameters from nmt_model_ffatt/translate.ckpt-3000\n",
      "  loaded infer model parameters from nmt_model_ffatt/translate.ckpt-3000, time 0.07s\n",
      "# External evaluation, global step 3000\n",
      "  decoding to output nmt_model_ffatt/output_dev.\n",
      "  done, num sentences 1553, num translations per input 1, time 14s, Fri Apr  6 05:18:18 2018.\n",
      "  bleu dev: 6.2\n",
      "  saving hparams to nmt_model_ffatt/hparams\n",
      "# External evaluation, global step 3000\n",
      "  decoding to output nmt_model_ffatt/output_test.\n",
      "  done, num sentences 1268, num translations per input 1, time 13s, Fri Apr  6 05:18:32 2018.\n",
      "  bleu test: 5.8\n",
      "  saving hparams to nmt_model_ffatt/hparams\n",
      "  step 3200 lr 0.0005 step-time 0.30s wps 15.16K ppl 26.64 gN 7.01 bleu 6.22, Fri Apr  6 05:18:58 2018\n",
      "  step 3300 lr 0.0005 step-time 0.17s wps 26.25K ppl 24.84 gN 6.56 bleu 6.22, Fri Apr  6 05:19:16 2018\n",
      "  step 3400 lr 0.00025 step-time 0.18s wps 26.39K ppl 24.88 gN 6.73 bleu 6.22, Fri Apr  6 05:19:34 2018\n",
      "  step 3500 lr 0.00025 step-time 0.17s wps 26.30K ppl 24.05 gN 6.65 bleu 6.22, Fri Apr  6 05:19:51 2018\n",
      "  step 3600 lr 0.00025 step-time 0.18s wps 26.25K ppl 24.14 gN 6.66 bleu 6.22, Fri Apr  6 05:20:09 2018\n",
      "  step 3700 lr 0.000125 step-time 0.17s wps 26.36K ppl 24.07 gN 6.68 bleu 6.22, Fri Apr  6 05:20:26 2018\n",
      "  step 3800 lr 0.000125 step-time 0.17s wps 26.39K ppl 24.35 gN 6.65 bleu 6.22, Fri Apr  6 05:20:44 2018\n",
      "  step 3900 lr 0.000125 step-time 0.17s wps 26.31K ppl 23.89 gN 6.64 bleu 6.22, Fri Apr  6 05:21:01 2018\n",
      "  step 4000 lr 6.25e-05 step-time 0.18s wps 26.40K ppl 24.02 gN 6.71 bleu 6.22, Fri Apr  6 05:21:19 2018\n",
      "# Save eval, global step 4000\n",
      "INFO:tensorflow:Restoring parameters from nmt_model_ffatt/translate.ckpt-4000\n",
      "  loaded infer model parameters from nmt_model_ffatt/translate.ckpt-4000, time 0.08s\n",
      "  # 1255\n",
      "    src: Đây là thành quả của những con người xuất sắc tại Văn phòng cơ học thành phố tại Boston .\n",
      "    ref: This is the work of the very smart people at the Office of New Urban Mechanics in Boston .\n",
      "    nmt: This is the of of <unk> who in in office room in in . . . &apos;s\n",
      "INFO:tensorflow:Restoring parameters from nmt_model_ffatt/translate.ckpt-4000\n",
      "  loaded eval model parameters from nmt_model_ffatt/translate.ckpt-4000, time 0.09s\n",
      "  eval dev: perplexity 38.87, time 2s, Fri Apr  6 05:21:21 2018.\n",
      "  eval test: perplexity 39.18, time 1s, Fri Apr  6 05:21:23 2018.\n",
      "INFO:tensorflow:Restoring parameters from nmt_model_ffatt/translate.ckpt-4000\n",
      "  loaded infer model parameters from nmt_model_ffatt/translate.ckpt-4000, time 0.08s\n",
      "  # 839\n",
      "    src: Điều họ cần là một văn hoá y học cần xác định lại .\n",
      "    ref: What they need is a redefined medical culture .\n",
      "    nmt: What they need is is need a <unk> culture .\n",
      "INFO:tensorflow:Restoring parameters from nmt_model_ffatt/translate.ckpt-4000\n",
      "  loaded eval model parameters from nmt_model_ffatt/translate.ckpt-4000, time 0.08s\n",
      "  eval dev: perplexity 38.87, time 2s, Fri Apr  6 05:21:32 2018.\n",
      "  eval test: perplexity 39.18, time 1s, Fri Apr  6 05:21:34 2018.\n",
      "INFO:tensorflow:Restoring parameters from nmt_model_ffatt/translate.ckpt-4000\n",
      "  loaded infer model parameters from nmt_model_ffatt/translate.ckpt-4000, time 0.07s\n",
      "# External evaluation, global step 4000\n",
      "  decoding to output nmt_model_ffatt/output_dev.\n",
      "  done, num sentences 1553, num translations per input 1, time 22s, Fri Apr  6 05:21:56 2018.\n",
      "  bleu dev: 6.8\n",
      "  saving hparams to nmt_model_ffatt/hparams\n",
      "# External evaluation, global step 4000\n",
      "  decoding to output nmt_model_ffatt/output_test.\n",
      "  done, num sentences 1268, num translations per input 1, time 21s, Fri Apr  6 05:22:18 2018.\n",
      "  bleu test: 6.4\n",
      "  saving hparams to nmt_model_ffatt/hparams\n",
      "# Final, step 4000 lr 6.25e-05 step-time 0.18s wps 26.40K ppl 24.02 gN 6.71 dev ppl 38.87, dev bleu 6.8, test ppl 39.18, test bleu 6.4, Fri Apr  6 05:22:18 2018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Done training!, time 758s, Fri Apr  6 05:22:18 2018.\n",
      "# Start evaluating saved best models.\n",
      "INFO:tensorflow:Restoring parameters from nmt_model_ffatt/best_bleu/translate.ckpt-4000\n",
      "  loaded infer model parameters from nmt_model_ffatt/best_bleu/translate.ckpt-4000, time 0.08s\n",
      "  # 993\n",
      "    src: Và vì sao đó , ngày nay trẻ em không sưu tập nữa .\n",
      "    ref: And somehow kids don &apos;t do that anymore .\n",
      "    nmt: And so , , , , children children not . . are\n",
      "INFO:tensorflow:Restoring parameters from nmt_model_ffatt/best_bleu/translate.ckpt-4000\n",
      "  loaded eval model parameters from nmt_model_ffatt/best_bleu/translate.ckpt-4000, time 0.08s\n",
      "  eval dev: perplexity 38.87, time 2s, Fri Apr  6 05:22:21 2018.\n",
      "  eval test: perplexity 39.18, time 1s, Fri Apr  6 05:22:22 2018.\n",
      "INFO:tensorflow:Restoring parameters from nmt_model_ffatt/best_bleu/translate.ckpt-4000\n",
      "  loaded infer model parameters from nmt_model_ffatt/best_bleu/translate.ckpt-4000, time 0.07s\n",
      "# External evaluation, global step 4000\n",
      "  decoding to output nmt_model_ffatt/output_dev.\n",
      "  done, num sentences 1553, num translations per input 1, time 22s, Fri Apr  6 05:22:45 2018.\n",
      "  bleu dev: 6.8\n",
      "  saving hparams to nmt_model_ffatt/hparams\n",
      "# External evaluation, global step 4000\n",
      "  decoding to output nmt_model_ffatt/output_test.\n",
      "  done, num sentences 1268, num translations per input 1, time 21s, Fri Apr  6 05:23:06 2018.\n",
      "  bleu test: 6.4\n",
      "  saving hparams to nmt_model_ffatt/hparams\n",
      "# Best bleu, step 4000 lr 6.25e-05 step-time 0.18s wps 26.40K ppl 24.02 gN 6.71 dev ppl 38.87, dev bleu 6.8, test ppl 39.18, test bleu 6.4, Fri Apr  6 05:23:06 2018\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'dev_ppl': 38.86918824457534,\n",
       "  'dev_scores': {'bleu': 6.777632076640572},\n",
       "  'test_ppl': 39.18415216194503,\n",
       "  'test_scores': {'bleu': 6.374063860686268}},\n",
       " 4000)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train an LSTM model with feedforward attention\n",
    "hparams = create_standard_hparams(data_path=os.path.join(\"datasets\", \"nmt_data_vi\"), \n",
    "                                  out_dir=\"nmt_model_ffatt\")\n",
    "hparams.add_hparam(\"attention_cell_class\", LSTMCellWithFeedForwardAttention)\n",
    "train(hparams, AttentionalModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
