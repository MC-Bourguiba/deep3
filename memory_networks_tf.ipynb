{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memory Networks\n",
    "\n",
    "So far, we have covered two components that have enable neural network models to solve textual tasks: **word embeddings** and **attention**. In this notebook, we will be introducing a **memory** component, which is relevant to cases in which long-term memory is needed, such as answering questions about a sequence of events.\n",
    "\n",
    "While RNNs do have a memory component in the form of a hidden state, this often does not sufficiently capture long-term dependencies, as such long-term information must be condensed into a single dense vector representation. Memory networks were designed to overcome this information bottleneck.\n",
    "\n",
    "In this notebook, we will build the base model for an end-to-end trainable memory network ([\"End-To-End Memory Networks\" (Sukhbaatar et al.)](https://arxiv.org/pdf/1503.08895.pdf].))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Ched/info/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import collections\n",
    "from functools import partial\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import zipfile\n",
    "\n",
    "import numpy as np\n",
    "from six.moves import urllib\n",
    "from six.moves import xrange\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Helper TensorFlow functions\n",
    "from utils import get_session, maybe_download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "You will evaluate your results on Facebook's bAbi dataset, which assesses performance on 20 different question answering tasks for reasoning over text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading babi_tasks_1-20_v1-2.tar.gz...\n",
      "Finished!\n",
      "Found and verified datasets/babi_tasks_1-20_v1-2.tar.gz\n",
      "Some housekeeping...\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "# Get Facebook's bAbi dataset\n",
    "from memn2n.babi_utils import get_babi_en\n",
    "\n",
    "#get_babi_en()\n",
    "\n",
    "# For 10K dataset, uncomment below:\n",
    "get_babi_en(get_10k=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MemN2N\n",
    "\n",
    "The base MemN2N model has the following components:\n",
    "\n",
    "## Input Map\n",
    "\n",
    "First, we will need to convert our data, which come in the form of **stories** (a list of facts, typically a description of events; e.g.,\n",
    "*joe go playground; bob go office; joe get football*), the **query** being asked about our story (e.g. *where is joe?*) and its respective **answer** into an internal feature representation.\n",
    "\n",
    "Here, we used an input map that assigns a unique ID to each word in the vocabulary of the stories and queries (built from words of the story and query of the test and training sets). The answer is one-hot encoded.\n",
    "\n",
    "As sentences vary in length, we pad sentences with a null symbol so they are padded to the same size. The value of the null embedding was chosen to be 0.\n",
    "\n",
    "You can find more details about this step in the `get_data_info` function of `memn2n/data_utils.py`.\n",
    "\n",
    "## Sentence Representation\n",
    "\n",
    "To represent the positions of words within a sentence, we will adopt positional encodings (PE) to allow the order of words to impact our memories. It takes the form:\n",
    "\n",
    "$$m_i = \\sum_{j}l_j \\cdot Ax_{ij}$$\n",
    "\n",
    "where $\\cdot$ is an element wise multiplication, and $l_j$ is a column vector with the following elements:\n",
    "\n",
    "$$l_{kj} = (1 - j / J) - (k/d)(1 - 2j/J)$$\n",
    "\n",
    "where $J$ is the number of words in the sentence and $d$ is the dimension of the embedding.\n",
    "\n",
    "## Q1A. Implement Position Encoding\n",
    "\n",
    "Open `memn2n/memn2n_skeleton.py` and fill in the `position_encoding` function.\n",
    "\n",
    "## Input Memory Representation\n",
    "\n",
    "Our inputs, $x_1,...,x_i$, for stories, queries, and answers need to be stored in memory, represented by memory vectors $m_1,...,m_i$ of dimension $d$. To accomplish this, we will use an embedding matrix A (of size $d \\times V$). We will use embedding matrix $B$ to represent the queries into an internal state $u$. \n",
    "\n",
    "The match between $u$ and each $m_i$ is computed by taking the inner product and a softmax:\n",
    "\n",
    "$$p_i = \\text{softmax}(u^Tm_i)$$\n",
    "\n",
    "## Output Memory Representation\n",
    "\n",
    "Each $x_i$ has a corresponding output vector $c_i$ which is given by another embedding matrix, $C$. The response from the memory $o$ is computed by taking the sum over the transformed inputs $c_i$ weighted by the probability vector from the input:\n",
    "\n",
    "$$o = \\sum_{i}p_ic_i$$\n",
    "\n",
    "# Generating Predictions\n",
    "\n",
    "In a single layer memory network, the sum of the output vector $o$ and input embedding $u$ is transformed by a weight matrix $W$ and passed through a softmax to generate a predicted answer.\n",
    "\n",
    "$$\\hat{a} = \\text{softmax}(W(o + u))$$\n",
    "\n",
    "To extend this to a multiple layer model, we will iterate over the memory $K$ times, or for $K$ **hops**, and adopt **adjacent weight tying.**\n",
    "\n",
    "The layers are stacked as such:\n",
    "\n",
    "* The question embedding is constrained to match the input embedding of the first layer: \n",
    "$$B = A^1$$\n",
    "\n",
    "\n",
    "* The output embedding for one layer is the input embedding for the layer above it: \n",
    "$$A^{k+1}= C^k$$\n",
    "\n",
    "\n",
    "* The inputs to all layers following the first is the sum of the output $o^k$ and the input $u^k$ from layer $k$: $$u^{k+1}=u^k+o^k$$\n",
    "\n",
    "\n",
    "* The input to W combines the input and output of the top memory layer: \n",
    "$$\\hat{a} = \\text{softmax}(W(o^k + u^k))$$\n",
    "\n",
    "\n",
    "* The answer prediction matrix is constrained to be the same as the final output embedding: \n",
    "$$W^T = C^K$$\n",
    "\n",
    "<figure>\n",
    "    <img src='images/arch.png' alt='missing' />\n",
    "    <figcaption>**Figure 1.** (a):  A single layer version of our model. (b):  A three layer version of our model. In practice, we will constrain several of the embedding matrices to be the same.\n",
    "    </figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2, Q3, Q4\n",
    "\n",
    "Implement the MemN2N model according to the above specifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from memn2n.memn2n_skeleton import MemN2N_Base\n",
    "\n",
    "class MemN2N(MemN2N_Base):\n",
    "        \n",
    "    def _build_inputs(self):\n",
    "        self._stories = tf.placeholder(tf.int32, [None, self._memory_size, self._sentence_size], name=\"stories\")\n",
    "        self._queries = tf.placeholder(tf.int32, [None, self._sentence_size], name=\"queries\")\n",
    "        self._answers = tf.placeholder(tf.int32, [None, self._vocab_size], name=\"answers\")\n",
    "        self._lr = tf.placeholder(tf.float32, [], name=\"learning_rate\")\n",
    "        \n",
    "    def _build_vars(self):\n",
    "        with tf.variable_scope(self._name):\n",
    "            nil_word_slot = tf.zeros([1, self._embedding_size])\n",
    "            A = tf.concat(axis=0, values=[ nil_word_slot, self._init([self._vocab_size-1, self._embedding_size]) ])\n",
    "            C = tf.concat(axis=0, values=[ nil_word_slot, self._init([self._vocab_size-1, self._embedding_size]) ])\n",
    "            \n",
    "            self.A_1 = tf.Variable(A, name=\"A\")\n",
    "            self.C = []\n",
    "\n",
    "            for hop in range(self._hops):\n",
    "                with tf.variable_scope('hop_{}'.format(hop)):\n",
    "                    self.C.append(tf.Variable(C, name=\"C\"))     \n",
    "        \n",
    "        self._nil_vars = set([self.A_1.name] + [x.name for x in self.C])\n",
    "    \n",
    "    \n",
    "    def _inference(self, stories, queries):\n",
    "        with tf.variable_scope(\"inference\"):\n",
    "            \n",
    "            \n",
    "            ##################################################\n",
    "            ### Q2 - Input memory representation           ###\n",
    "            ##################################################\n",
    "            \n",
    "            q_emb = tf.nn.embedding_lookup(self.A_1, queries) # YOUR CODE HERE\n",
    "            u = [tf.reduce_sum(q_emb * self._encoding, 1)] # YOUR CODE HERE\n",
    "            \n",
    "            for hop in range(self._hops):\n",
    "                if hop == 0:\n",
    "                    input_emb = tf.nn.embedding_lookup(self.A_1, stories) # YOUR CODE HERE\n",
    "                    # Remember to element wise multiply position encoding!\n",
    "                    m_A = tf.reduce_sum(input_emb * self._encoding, 2) # YOUR CODE HERE\n",
    "                    \n",
    "                    \n",
    "                else:\n",
    "                    with tf.variable_scope('hop_{}'.format(hop - 1)):\n",
    "                        # YOUR CODE HERE\n",
    "                        imput_emb = tf.nn.embedding_lookup(self.C[hop - 1], stories)\n",
    "                        m_A = tf.reduce_sum(input_emb * self._encoding, 2)\n",
    "                        \n",
    "                        \n",
    "           \n",
    "                u_temp = tf.transpose(tf.expand_dims(u[-1], -1), [0, 2, 1])\n",
    "                dot_prod = tf.reduce_sum(m_A * u_temp, 2)\n",
    "                probs = tf.nn.softmax(dot_prod)\n",
    "\n",
    "                ##################################################\n",
    "                ### Q3 - Output memory representation          ###\n",
    "                ##################################################\n",
    "                \n",
    "                with tf.variable_scope('hop_{}'.format(hop)):\n",
    "                    out_emb = tf.nn.embedding_lookup(self.C[hop], \n",
    "                                                     stories) # YOUR CODE HERE\n",
    "                # Remember to element wise multiply position encoding!\n",
    "                m_C = tf.reduce_sum(out_emb*self._encoding, 2)# YOUR CODE HERE\n",
    "                o_k = tf.reduce_sum(tf.transpose(tf.expand_dims(probs, -1), \n",
    "                                                 [0, 2, 1])*tf.transpose(m_C, \n",
    "                                                                         [0,2,1]),2)\n",
    "                                    # YOUR CODE HERE\n",
    "\n",
    "                ##################################################\n",
    "                ### Q4 - Generating predictions                ###\n",
    "                ##################################################\n",
    "                \n",
    "                u_k = u[-1] + o_k #\n",
    "                u.append(u_k)\n",
    "                \n",
    "            # Final output embedding, W_T = C_K from adjacent weight sharing\n",
    "            with tf.variable_scope('hop_{}'.format(self._hops)):\n",
    "                return tf.nn.softmax(tf.matmul(u_k, \n",
    "                                               tf.transpose(self.C[-1], \n",
    "                                                            [1,0]))) # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training:\n",
    "\n",
    "We will now evaluate your MemN2N implementation on Facebook's bAbi dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "\n",
    "from memn2n.data_utils import get_data_info, split_train_valid_test, generate_batches\n",
    "from sklearn import metrics\n",
    "from six.moves import range\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter intialization\n",
    "\n",
    "# Hyperparameters\n",
    "learning_rate = 0.01 # Learning rate for the Adam Optimizer\n",
    "lr_decay_epoch = 25 # Number of epochs until lr is halved\n",
    "lr_decay_stop = 100 # Epoch to stop annealing lr\n",
    "max_grad_norm = 40 # Clip gradients to this norm\n",
    "\n",
    "hops = 3 # Number of hops\n",
    "embedding_size = 20 # Embedding size for embedding matrices\n",
    "memory_size = 50 # Maximum size of memory\n",
    "\n",
    "epochs = 60\n",
    "batch_size = 32\n",
    "evaluation_interval = 10\n",
    "data_dir = \"datasets/babi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Ched/info/lib/python3.6/re.py:212: FutureWarning: split() requires a non-empty pattern match.\n",
      "  return _compile(pattern, flags).split(string, maxsplit)\n"
     ]
    }
   ],
   "source": [
    "# Get data and process for our model\n",
    "word_idx, vocab_size, sentence_size = get_data_info(data_dir, memory_size)\n",
    "\n",
    "train_stories, train_queries, train_answers, \\\n",
    "val_stories, val_queries, val_answers, \\\n",
    "test_stories, test_queries, test_answers = split_train_valid_test(data_dir, word_idx, sentence_size, memory_size)\n",
    "\n",
    "# Number of train/val/test examples\n",
    "n_train = train_stories.shape[0]\n",
    "n_val = val_stories.shape[0]\n",
    "n_test = test_stories.shape[0]\n",
    "\n",
    "# Create labels\n",
    "train_labels = np.argmax(train_answers, axis=1)\n",
    "test_labels = np.argmax(test_answers, axis=1)\n",
    "val_labels = np.argmax(val_answers, axis=1)\n",
    "\n",
    "# Generate batches\n",
    "batches = generate_batches(batch_size, n_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "None values not supported.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-64d3ba374d15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     model = MemN2N(batch_size, vocab_size, sentence_size, memory_size, embedding_size, session=sess,\n\u001b[0;32m---> 10\u001b[0;31m                    hops=hops, max_grad_norm=max_grad_norm)\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/assignment3 2/memn2n/memn2n_skeleton.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch_size, vocab_size, sentence_size, memory_size, embedding_size, hops, max_grad_norm, initializer, encoding, session, name)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;31m# gradient pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mgrads_and_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_opt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0mgrads_and_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_by_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_max_grad_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0mgrads_and_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madd_gradient_noise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mnil_grads_and_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/assignment3 2/memn2n/memn2n_skeleton.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;31m# gradient pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mgrads_and_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_opt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0mgrads_and_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_by_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_max_grad_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0mgrads_and_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madd_gradient_noise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mnil_grads_and_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/info/lib/python3.6/site-packages/tensorflow/python/ops/clip_ops.py\u001b[0m in \u001b[0;36mclip_by_norm\u001b[0;34m(t, clip_norm, axes, name)\u001b[0m\n\u001b[1;32m    105\u001b[0m   \"\"\"\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"clip_by_norm\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip_norm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"t\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;31m# Calculate L2-norm, clip elements by ratio of clip_norm to L2-norm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/info/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, preferred_dtype)\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 836\u001b[0;31m       as_ref=False)\n\u001b[0m\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/info/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, ctx)\u001b[0m\n\u001b[1;32m    924\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/info/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    227\u001b[0m                                          as_ref=False):\n\u001b[1;32m    228\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/info/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name, verify_shape)\u001b[0m\n\u001b[1;32m    206\u001b[0m   tensor_value.tensor.CopyFrom(\n\u001b[1;32m    207\u001b[0m       tensor_util.make_tensor_proto(\n\u001b[0;32m--> 208\u001b[0;31m           value, dtype=dtype, shape=shape, verify_shape=verify_shape))\n\u001b[0m\u001b[1;32m    209\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m   const_tensor = g.create_op(\n",
      "\u001b[0;32m~/info/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    369\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"None values not supported.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m     \u001b[0;31m# if dtype is provided, forces numpy array to be the type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m     \u001b[0;31m# provided if possible.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: None values not supported."
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "\n",
    "# Accuracy Results\n",
    "train_eval = None\n",
    "val_eval = None\n",
    "test_eval = None\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    model = MemN2N(batch_size, vocab_size, sentence_size, memory_size, embedding_size, session=sess,\n",
    "                   hops=hops, max_grad_norm=max_grad_norm)\n",
    "    for i in range(1, epochs):\n",
    "        \n",
    "        # Stepped learning rate\n",
    "        if i - 1 <= lr_decay_stop:\n",
    "            anneal = 2.0 ** ((i - 1) // lr_decay_epoch)\n",
    "        else:\n",
    "            anneal = 2.0 ** (lr_decay_stop // lr_decay_epoch)\n",
    "        lr = learning_rate / anneal\n",
    "\n",
    "        np.random.shuffle(batches)\n",
    "        total_cost = 0.0\n",
    "        for start, end in batches:\n",
    "            s = train_stories[start:end]\n",
    "            q = train_queries[start:end]\n",
    "            a = train_answers[start:end]\n",
    "            cost_t = model.batch_fit(s, q, a, lr)\n",
    "            total_cost += cost_t\n",
    "\n",
    "        if i % evaluation_interval == 0:\n",
    "            train_accs = []\n",
    "            for start in range(0, n_train, n_train//20):\n",
    "                end = start + n_train//20\n",
    "                s = train_stories[start:end]\n",
    "                q = train_queries[start:end]\n",
    "                pred = model.predict(s, q)\n",
    "                acc = metrics.accuracy_score(pred, train_labels[start:end])\n",
    "                train_accs.append(acc)\n",
    "\n",
    "            val_accs = []\n",
    "            for start in range(0, n_val, n_val//20):\n",
    "                end = start + n_val//20\n",
    "                s = val_stories[start:end]\n",
    "                q = val_queries[start:end]\n",
    "                pred = model.predict(s, q)\n",
    "                acc = metrics.accuracy_score(pred, val_labels[start:end])\n",
    "                val_accs.append(acc)\n",
    "\n",
    "            test_accs = []\n",
    "            for start in range(0, n_test, n_test//20):\n",
    "                end = start + n_test//20\n",
    "                s = test_stories[start:end]\n",
    "                q = test_queries[start:end]\n",
    "                pred = model.predict(s, q)\n",
    "                acc = metrics.accuracy_score(pred, test_labels[start:end])\n",
    "                test_accs.append(acc)\n",
    "\n",
    "            print('-----------------------')\n",
    "            print('Epoch', i)\n",
    "            print('Total Cost:', total_cost)\n",
    "            print()\n",
    "            t = 1\n",
    "            for t1, t2, t3 in zip(train_accs, val_accs, test_accs):\n",
    "                print(\"Task {}\".format(t))\n",
    "                print(\"Training Accuracy = {}\".format(t1))\n",
    "                print(\"Validation Accuracy = {}\".format(t2))\n",
    "                print(\"Testing Accuracy = {}\".format(t3))\n",
    "                print()\n",
    "                t += 1\n",
    "            print('-----------------------')\n",
    "        \n",
    "        if i == epochs:\n",
    "            train_eval, val_eval, test_eval = train_accs, val_accs, test_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View results in pd dataframe\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "df = pd.DataFrame({\n",
    "    'Training Accuracy': train_accs,\n",
    "    'Validation Accuracy': val_accs,\n",
    "    'Testing Accuracy': test_accs\n",
    "    }, index=range(1, 21))\n",
    "df.index.name = 'Task'\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
